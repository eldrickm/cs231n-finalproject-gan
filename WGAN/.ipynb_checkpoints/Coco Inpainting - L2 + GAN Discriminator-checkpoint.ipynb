{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f05f578d530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000)  # fix seed\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_dataset = dset.CocoCaptions(\n",
    "    root='inpainting/train2014',\n",
    "    annFile='inpainting/annotations/captions_train2014.json',\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterator(object):\n",
    "    \"\"\"Data Iterator for COCO.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path='inpainting/train2014',\n",
    "        dev_path='inpainting/val2014',\n",
    "        train_annotation_path='inpainting/annotations/captions_train2014.json',\n",
    "        dev_annotation_path='inpainting/annotations/captions_val2014.json',\n",
    "    ):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        self.train_path = train_path\n",
    "        self.train_annotation_path = train_annotation_path\n",
    "        self.dev_path = dev_path\n",
    "        self.dev_annotation_path = dev_annotation_path\n",
    "        print('Processing data ...')\n",
    "        self._get_real_and_fake_images()\n",
    "\n",
    "    def _get_real_and_fake_images(self):\n",
    "        \"\"\"Get real and fake images from path.\"\"\"\n",
    "        self.train_dataset = dset.CocoCaptions(\n",
    "            root=self.train_path,\n",
    "            annFile=self.train_annotation_path,\n",
    "            transform=transforms.ToTensor()\n",
    "        )\n",
    "        self.valid_dataset = dset.CocoCaptions(\n",
    "            root=self.dev_path, \n",
    "            annFile=self.dev_annotation_path,\n",
    "            transform=transforms.ToTensor()\n",
    "        )\n",
    "        \n",
    "        print('Populating training images & captions ...')\n",
    "        train_images = []\n",
    "        train_captions = []\n",
    "        \n",
    "        # There appears to be one image missing for some weird reason.\n",
    "        try:\n",
    "            for img, captions in self.train_dataset:\n",
    "                train_images.append(img)\n",
    "                train_captions.append(captions)\n",
    "        except IOError:\n",
    "            pass\n",
    "        \n",
    "        train_images = torch.stack(train_images)\n",
    "        \n",
    "        print('Populating validation images ...')\n",
    "        valid_images = torch.stack([x[0] for x in self.valid_dataset])\n",
    "        valid_captions = [x[1] for x in self.valid_dataset]\n",
    "        \n",
    "        print('Cropping 32x32 patch for training images ...')\n",
    "        noisy_train_images = copy.deepcopy(train_images.numpy())\n",
    "        noisy_train_images[:, :, 16:48, 16:48] = 0\n",
    "        noisy_train_images = torch.from_numpy(noisy_train_images)\n",
    "\n",
    "        print('Cropping 32x32 patch for validation images ...')\n",
    "        noisy_valid_images = copy.deepcopy(valid_images.numpy())\n",
    "        noisy_valid_images[:, :, 16:48, 16:48] = 0\n",
    "        noisy_valid_images = torch.from_numpy(noisy_valid_images)\n",
    "        \n",
    "        self.train_images = train_images\n",
    "        self.valid_images = valid_images\n",
    "\n",
    "        self.noisy_train_images = noisy_train_images\n",
    "        self.noisy_valid_images = noisy_valid_images\n",
    "        \n",
    "        self.num_train = len(train_images)\n",
    "        self.num_valid = len(valid_images)\n",
    "\n",
    "    def get_train_minibatch(self, index, batch_size):\n",
    "        \"\"\"Return a minibatch of real and fake examples.\"\"\"\n",
    "        real_examples = Variable(self.train_images[index: index + batch_size]).cuda()\n",
    "        fake_examples = Variable(self.noisy_train_images[index: index + batch_size]).cuda()\n",
    "        return real_examples, real_examples[:, :, 16:48, 16:48], fake_examples\n",
    "\n",
    "    def get_valid_minibatch(self, index, batch_size):\n",
    "        \"\"\"Return a minibatch of real and fake examples.\"\"\"\n",
    "        real_examples = Variable(self.valid_images[index: index + batch_size]).cuda()\n",
    "        fake_examples = Variable(self.noisy_valid_images[index: index + batch_size]).cuda()\n",
    "        \n",
    "        return real_examples, real_examples[:, :, 16:48, 16:48], fake_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data ...\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "Populating training images & captions ...\n",
      "Populating validation images ...\n",
      "Cropping 32x32 patch for training images ...\n",
      "Cropping 32x32 patch for validation images ...\n"
     ]
    }
   ],
   "source": [
    "iterator = DataIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(iterator.train_images[14].numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(iterator.noisy_train_images[14].numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    \"\"\"Generator module.\"\"\"\n",
    "\n",
    "    def __init__(self, start_filter):\n",
    "        \"\"\"Initialize generator.\"\"\"\n",
    "        super(UNetGenerator, self).__init__()\n",
    "\n",
    "        #################################\n",
    "        ####### DOWNSAMPLER MODULE ######\n",
    "        #################################\n",
    "\n",
    "        # 3 x 64 x 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=start_filter, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(start_filter)\n",
    "\n",
    "        # 16 x 32 x 32\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=start_filter, out_channels=start_filter * 2,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(start_filter * 2)\n",
    "\n",
    "        # 32 x 16 x 16\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=start_filter * 2, out_channels=start_filter * 3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(start_filter * 3)\n",
    "\n",
    "        # 64 x 8 x 8\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=start_filter * 3, out_channels=start_filter * 4,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(start_filter * 4)\n",
    "\n",
    "        #################################\n",
    "        ####### UPSAMPLER MODULE ########\n",
    "        #################################\n",
    "\n",
    "        # 128 x 4 x 4\n",
    "        self.tconv1 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 4, out_channels=start_filter * 3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tbn1 = nn.BatchNorm2d(start_filter * 3)\n",
    "\n",
    "        # 64 x 8 x 8\n",
    "        self.tconv2 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 3, out_channels=start_filter * 2,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tbn2 = nn.BatchNorm2d(start_filter * 2)\n",
    "\n",
    "        # 32 x 16 x 16\n",
    "        self.tconv3 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 2, out_channels=start_filter,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tbn3 = nn.BatchNorm2d(start_filter)\n",
    "\n",
    "        # 16 x 32 x 32\n",
    "        self.tconv4 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter, out_channels=3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        # Finally - 3 x 64 x 64\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Propogate input through the generator.\"\"\"\n",
    "        # Downsampling steps.\n",
    "        conv1 = F.relu(self.bn1(self.conv1(input)))\n",
    "        conv2 = F.relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.bn4(self.conv4(conv3)))\n",
    "\n",
    "        # Upsampling steps.\n",
    "        tconv1 = F.relu(self.tbn1(self.tconv1(conv4)))\n",
    "        tconv2 = F.relu(self.tbn2(self.tconv2(tconv1)))\n",
    "        tconv3 = F.relu(self.tbn3(self.tconv3(tconv2)))\n",
    "        tconv4 = F.tanh(self.tconv4(tconv3))\n",
    "\n",
    "        return tconv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGeneratorSkip(nn.Module):\n",
    "    \"\"\"Generator module.\"\"\"\n",
    "\n",
    "    def __init__(self, start_filter):\n",
    "        \"\"\"Initialize generator.\"\"\"\n",
    "        super(UNetGeneratorSkip, self).__init__()\n",
    "\n",
    "        #################################\n",
    "        ####### DOWNSAMPLER MODULE ######\n",
    "        #################################\n",
    "\n",
    "        # 3 x 64 x 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=start_filter, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(start_filter)\n",
    "\n",
    "        # 16 x 32 x 32\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=start_filter, out_channels=start_filter * 2,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(start_filter * 2)\n",
    "\n",
    "        # 32 x 16 x 16\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=start_filter * 2, out_channels=start_filter * 3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(start_filter * 3)\n",
    "\n",
    "        # 48 x 8 x 8\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=start_filter * 3, out_channels=start_filter * 4,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(start_filter * 4)\n",
    "\n",
    "        #################################\n",
    "        ####### UPSAMPLER MODULE ########\n",
    "        #################################\n",
    "\n",
    "        # 64 x 4 x 4\n",
    "        self.tconv1 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 4, out_channels=start_filter * 3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tbn1 = nn.BatchNorm2d(start_filter * 3)\n",
    "\n",
    "        # 48 x 8 x 8 + 48 x 8 x 8 = [96 x 8 x 8]\n",
    "        self.tconv2 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 6, out_channels=start_filter * 2,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.tbn2 = nn.BatchNorm2d(start_filter * 2)\n",
    "\n",
    "        # 32 x 16 x 16 + 32 x 16 x 16 = [64 x 16 x 16]\n",
    "        self.tconv3 = nn.ConvTranspose2d(\n",
    "            in_channels=start_filter * 4, out_channels=3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Propogate input through the generator.\"\"\"\n",
    "        # Downsampling steps.\n",
    "        conv1 = F.relu(self.bn1(self.conv1(input)))\n",
    "        conv2 = F.relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = F.relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = F.relu(self.bn4(self.conv4(conv3)))\n",
    "\n",
    "        # Upsampling steps.\n",
    "        tconv1 = F.relu(self.tbn1(self.tconv1(conv4)))\n",
    "        tconv1 = torch.cat((tconv1, conv3), 1)\n",
    "\n",
    "        tconv2 = F.relu(self.tbn2(self.tconv2(tconv1)))\n",
    "        tconv2 = torch.cat((tconv2, conv2), 1)\n",
    "\n",
    "        tconv3 = F.sigmoid(self.tconv3(tconv2))\n",
    "\n",
    "        return tconv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator.\"\"\"\n",
    "\n",
    "    def __init__(self, start_filter):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 3 x 32 x 32\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=start_filter, kernel_size=4,\n",
    "            stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(start_filter)\n",
    "\n",
    "        # 16 x 16 x 16\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=start_filter, out_channels=start_filter * 2,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(start_filter * 2)\n",
    "\n",
    "        # 32 x 8 x 8\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=start_filter * 2, out_channels=start_filter * 3,\n",
    "            kernel_size=4, stride=2, padding=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(start_filter * 3)\n",
    "\n",
    "        # 48 x 4 x 4\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=start_filter * 3, out_channels=start_filter * 4,\n",
    "            kernel_size=4, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn4 = nn.BatchNorm2d(start_filter * 4)\n",
    "\n",
    "        # 64 x 2 x 2\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=start_filter * 4, out_channels=1,\n",
    "            kernel_size=2, stride=2, padding=0, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Propogate input through the network.\"\"\"\n",
    "        # Downsampling steps.\n",
    "        # print 'input', input.size()\n",
    "        conv1 = F.leaky_relu(self.bn1(self.conv1(input)))\n",
    "        conv2 = F.leaky_relu(self.bn2(self.conv2(conv1)))\n",
    "        conv3 = F.leaky_relu(self.bn3(self.conv3(conv2)))\n",
    "        conv4 = F.leaky_relu(self.bn4(self.conv4(conv3)))\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        return conv5.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNetGeneratorSkip(start_filter=32).cuda()\n",
    "discriminator = Discriminator(start_filter=32).cuda()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "clamp_lower = -0.03\n",
    "clamp_upper = 0.03\n",
    "loss_criterion = nn.MSELoss().cuda()\n",
    "save_dir = 'inpainting/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(epoch, fake_images, real_images, real_examples_full):\n",
    "    j = np.random.randint(low=0, high=500)\n",
    "    real_examples_full, real_examples, fake_images = iterator.get_valid_minibatch(j, 32)\n",
    "    generator.eval()\n",
    "    reconstructions = generator(fake_images)\n",
    "    # fig = plt.figure(figsize=(20, 40))\n",
    "    # idx = 1\n",
    "    reconstructions = reconstructions.data.cpu().numpy()\n",
    "    real = real_examples_full.data.cpu().numpy()\n",
    "    real_copy = copy.deepcopy(real)\n",
    "    real_copy[:, :, 16:48, 16:48] = reconstructions\n",
    "    real_copy = torch.from_numpy(real_copy)\n",
    "    real = torch.from_numpy(real)\n",
    "    out_tensor = torch.zeros(1, real_copy.size(1), real_copy.size(2), real_copy.size(3))\n",
    "    for zz, zzz in zip(real_copy[:10], real[:10]):\n",
    "        out_tensor = torch.cat([out_tensor, zz.unsqueeze(0)])\n",
    "        out_tensor = torch.cat([out_tensor, zzz.unsqueeze(0)])\n",
    "    vutils.save_image(out_tensor[1:], 'inpainting/samples/epoch_%d_samples.png' % (epoch), normalize=True, scale_each=True, nrow=4)\n",
    "    generator.train()\n",
    "    '''\n",
    "    for reconstruction, real_ in zip(real_copy[:20], real[:20]):\n",
    "        fig.add_subplot(5, 8, idx)\n",
    "        plt.imshow(reconstruction.transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        fig.add_subplot(5, 8, idx + 1)\n",
    "        plt.imshow(real_.transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        idx += 2\n",
    "    plt.savefig('samples/epoch_%d_samples' % (epoch))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss_D: -0.527335 Loss_G: 0.344586\n",
      "[1] Loss_D: -0.598612 Loss_G: 0.345459\n",
      "[2] Loss_D: -0.604713 Loss_G: 0.342991\n",
      "[3] Loss_D: -0.606759 Loss_G: 0.340252\n",
      "[4] Loss_D: -0.607872 Loss_G: 0.338054\n",
      "[5] Loss_D: -0.608034 Loss_G: 0.336672\n",
      "[6] Loss_D: -0.360221 Loss_G: 0.283841\n",
      "[7] Loss_D: -0.391369 Loss_G: 0.239850\n",
      "[8] Loss_D: -0.491920 Loss_G: 0.327669\n",
      "[9] Loss_D: -0.481456 Loss_G: 0.317145\n",
      "[10] Loss_D: -0.448828 Loss_G: 0.254254\n",
      "[11] Loss_D: -0.525069 Loss_G: 0.259937\n",
      "[12] Loss_D: -0.377849 Loss_G: 0.307451\n",
      "[13] Loss_D: -0.390373 Loss_G: 0.217140\n",
      "[14] Loss_D: -0.582068 Loss_G: 0.340316\n",
      "[15] Loss_D: -0.466581 Loss_G: 0.282625\n",
      "[16] Loss_D: -0.423361 Loss_G: 0.223463\n",
      "[17] Loss_D: -0.526897 Loss_G: 0.295147\n",
      "[18] Loss_D: -0.492001 Loss_G: 0.253843\n",
      "[19] Loss_D: -0.445652 Loss_G: 0.257758\n",
      "[20] Loss_D: -0.500119 Loss_G: 0.307358\n",
      "[21] Loss_D: -0.457240 Loss_G: 0.224231\n",
      "[22] Loss_D: -0.595051 Loss_G: 0.338695\n",
      "[23] Loss_D: -0.392342 Loss_G: 0.288073\n",
      "[24] Loss_D: -0.561059 Loss_G: 0.337126\n",
      "[25] Loss_D: -0.514744 Loss_G: 0.332882\n",
      "[26] Loss_D: -0.561753 Loss_G: 0.340599\n",
      "[27] Loss_D: -0.587519 Loss_G: 0.338435\n",
      "[28] Loss_D: -0.343794 Loss_G: 0.122087\n",
      "[29] Loss_D: -0.350356 Loss_G: 0.202613\n",
      "[30] Loss_D: -0.451808 Loss_G: 0.307273\n",
      "[31] Loss_D: -0.532514 Loss_G: 0.331483\n",
      "[32] Loss_D: -0.376471 Loss_G: 0.310469\n",
      "[33] Loss_D: -0.519371 Loss_G: 0.326116\n",
      "[34] Loss_D: -0.550189 Loss_G: 0.326462\n",
      "[35] Loss_D: -0.555445 Loss_G: 0.328840\n",
      "[36] Loss_D: -0.550458 Loss_G: 0.330068\n",
      "[37] Loss_D: -0.557699 Loss_G: 0.329627\n",
      "[38] Loss_D: -0.580299 Loss_G: 0.331535\n",
      "[39] Loss_D: -0.484076 Loss_G: 0.266658\n",
      "[40] Loss_D: -0.467373 Loss_G: 0.316759\n",
      "[41] Loss_D: -0.389246 Loss_G: 0.309126\n",
      "[42] Loss_D: -0.503876 Loss_G: 0.321178\n",
      "[43] Loss_D: -0.486681 Loss_G: 0.275142\n",
      "[44] Loss_D: -0.508083 Loss_G: 0.320887\n",
      "[45] Loss_D: -0.546442 Loss_G: 0.324663\n",
      "[46] Loss_D: -0.512618 Loss_G: 0.282212\n",
      "[47] Loss_D: -0.539733 Loss_G: 0.343841\n",
      "[48] Loss_D: -0.589213 Loss_G: 0.336538\n",
      "[49] Loss_D: -0.593302 Loss_G: 0.333100\n",
      "[50] Loss_D: -0.595190 Loss_G: 0.331716\n",
      "[51] Loss_D: -0.351148 Loss_G: 0.302536\n",
      "[52] Loss_D: -0.402774 Loss_G: 0.292158\n",
      "[53] Loss_D: -0.437474 Loss_G: 0.308245\n",
      "[54] Loss_D: -0.390152 Loss_G: 0.303899\n",
      "[55] Loss_D: -0.438833 Loss_G: 0.313130\n",
      "[56] Loss_D: -0.498589 Loss_G: 0.318665\n",
      "[57] Loss_D: -0.482377 Loss_G: 0.285188\n",
      "[58] Loss_D: -0.546530 Loss_G: 0.323033\n",
      "[59] Loss_D: -0.411138 Loss_G: 0.308114\n",
      "[60] Loss_D: -0.500017 Loss_G: 0.318593\n",
      "[61] Loss_D: -0.537452 Loss_G: 0.323627\n",
      "[62] Loss_D: -0.493940 Loss_G: 0.311135\n",
      "[63] Loss_D: -0.546712 Loss_G: 0.323568\n",
      "[64] Loss_D: -0.566046 Loss_G: 0.324443\n",
      "[65] Loss_D: -0.553824 Loss_G: 0.321299\n",
      "[66] Loss_D: -0.501633 Loss_G: 0.297186\n",
      "[67] Loss_D: -0.582893 Loss_G: 0.328987\n",
      "[68] Loss_D: -0.390002 Loss_G: 0.224510\n",
      "[69] Loss_D: -0.512804 Loss_G: 0.317431\n",
      "[70] Loss_D: -0.557785 Loss_G: 0.323022\n",
      "[71] Loss_D: -0.475624 Loss_G: 0.313332\n",
      "[72] Loss_D: -0.490000 Loss_G: 0.269754\n",
      "[73] Loss_D: -0.541803 Loss_G: 0.320734\n",
      "[74] Loss_D: -0.478659 Loss_G: 0.310822\n",
      "[75] Loss_D: -0.532838 Loss_G: 0.318306\n",
      "[76] Loss_D: -0.557638 Loss_G: 0.322505\n",
      "[77] Loss_D: -0.576311 Loss_G: 0.322812\n",
      "[78] Loss_D: -0.581383 Loss_G: 0.323682\n",
      "[79] Loss_D: -0.460937 Loss_G: 0.280311\n",
      "[80] Loss_D: -0.440697 Loss_G: 0.204839\n",
      "[81] Loss_D: -0.431323 Loss_G: 0.291290\n",
      "[82] Loss_D: -0.342206 Loss_G: 0.170341\n",
      "[83] Loss_D: -0.536638 Loss_G: 0.334934\n",
      "[84] Loss_D: -0.276123 Loss_G: 0.284225\n",
      "[85] Loss_D: -0.404717 Loss_G: 0.287276\n",
      "[86] Loss_D: -0.401912 Loss_G: 0.303494\n",
      "[87] Loss_D: -0.352840 Loss_G: 0.194222\n",
      "[88] Loss_D: -0.397515 Loss_G: 0.285144\n",
      "[89] Loss_D: -0.511050 Loss_G: 0.318725\n",
      "[90] Loss_D: -0.404380 Loss_G: 0.235218\n",
      "[91] Loss_D: -0.456756 Loss_G: 0.303419\n",
      "[92] Loss_D: -0.388418 Loss_G: 0.294420\n",
      "[93] Loss_D: -0.374002 Loss_G: 0.300001\n",
      "[94] Loss_D: -0.392419 Loss_G: 0.287016\n",
      "[95] Loss_D: -0.492604 Loss_G: 0.301868\n",
      "[96] Loss_D: -0.471103 Loss_G: 0.318290\n",
      "[97] Loss_D: -0.485010 Loss_G: 0.314881\n",
      "[98] Loss_D: -0.488259 Loss_G: 0.312762\n",
      "[99] Loss_D: -0.450093 Loss_G: 0.272308\n",
      "[100] Loss_D: -0.500274 Loss_G: 0.309673\n",
      "[101] Loss_D: -0.504089 Loss_G: 0.323928\n",
      "[102] Loss_D: -0.459677 Loss_G: 0.259933\n",
      "[103] Loss_D: -0.567462 Loss_G: 0.330233\n",
      "[104] Loss_D: -0.387058 Loss_G: 0.240796\n",
      "[105] Loss_D: -0.438858 Loss_G: 0.306343\n",
      "[106] Loss_D: -0.465550 Loss_G: 0.311140\n",
      "[107] Loss_D: -0.464263 Loss_G: 0.308448\n",
      "[108] Loss_D: -0.500729 Loss_G: 0.312422\n",
      "[109] Loss_D: -0.530424 Loss_G: 0.317973\n",
      "[110] Loss_D: -0.559634 Loss_G: 0.320191\n",
      "[111] Loss_D: -0.572872 Loss_G: 0.322020\n",
      "[112] Loss_D: -0.541688 Loss_G: 0.318081\n",
      "[113] Loss_D: -0.575654 Loss_G: 0.321331\n",
      "[114] Loss_D: -0.581959 Loss_G: 0.321617\n",
      "[115] Loss_D: -0.582548 Loss_G: 0.321901\n",
      "[116] Loss_D: -0.583153 Loss_G: 0.321902\n",
      "[117] Loss_D: -0.433008 Loss_G: 0.306903\n",
      "[118] Loss_D: -0.497069 Loss_G: 0.306818\n",
      "[119] Loss_D: -0.520751 Loss_G: 0.312566\n",
      "[120] Loss_D: -0.496936 Loss_G: 0.269356\n",
      "[121] Loss_D: -0.497733 Loss_G: 0.289597\n",
      "[122] Loss_D: -0.537878 Loss_G: 0.318433\n",
      "[123] Loss_D: -0.511085 Loss_G: 0.309659\n",
      "[124] Loss_D: -0.558478 Loss_G: 0.318368\n",
      "[125] Loss_D: -0.555601 Loss_G: 0.316377\n",
      "[126] Loss_D: -0.562193 Loss_G: 0.315964\n",
      "[127] Loss_D: -0.572653 Loss_G: 0.318887\n",
      "[128] Loss_D: -0.543784 Loss_G: 0.313903\n",
      "[129] Loss_D: -0.529127 Loss_G: 0.314023\n",
      "[130] Loss_D: -0.565807 Loss_G: 0.317781\n",
      "[131] Loss_D: -0.547984 Loss_G: 0.309984\n",
      "[132] Loss_D: -0.553340 Loss_G: 0.312240\n",
      "[133] Loss_D: -0.561306 Loss_G: 0.317560\n",
      "[134] Loss_D: -0.549569 Loss_G: 0.314988\n",
      "[135] Loss_D: -0.550433 Loss_G: 0.315865\n",
      "[136] Loss_D: -0.552892 Loss_G: 0.316590\n",
      "[137] Loss_D: -0.578146 Loss_G: 0.318565\n",
      "[138] Loss_D: -0.580492 Loss_G: 0.318376\n",
      "[139] Loss_D: -0.579142 Loss_G: 0.317500\n",
      "[140] Loss_D: -0.542375 Loss_G: 0.314692\n",
      "[141] Loss_D: -0.553161 Loss_G: 0.314406\n",
      "[142] Loss_D: -0.524190 Loss_G: 0.311399\n",
      "[143] Loss_D: -0.562604 Loss_G: 0.315685\n",
      "[144] Loss_D: -0.521226 Loss_G: 0.294645\n",
      "[145] Loss_D: -0.572266 Loss_G: 0.316783\n",
      "[146] Loss_D: -0.558350 Loss_G: 0.315184\n",
      "[147] Loss_D: -0.571912 Loss_G: 0.315278\n",
      "[148] Loss_D: -0.534997 Loss_G: 0.311721\n",
      "[149] Loss_D: -0.522875 Loss_G: 0.310816\n",
      "[150] Loss_D: -0.572271 Loss_G: 0.315704\n",
      "[151] Loss_D: -0.579535 Loss_G: 0.316080\n",
      "[152] Loss_D: -0.575682 Loss_G: 0.314937\n",
      "[153] Loss_D: -0.535842 Loss_G: 0.308184\n",
      "[154] Loss_D: -0.553139 Loss_G: 0.313247\n",
      "[155] Loss_D: -0.519569 Loss_G: 0.298506\n",
      "[156] Loss_D: -0.504327 Loss_G: 0.306402\n",
      "[157] Loss_D: -0.563194 Loss_G: 0.315298\n",
      "[158] Loss_D: -0.574500 Loss_G: 0.315508\n",
      "[159] Loss_D: -0.576739 Loss_G: 0.314928\n",
      "[160] Loss_D: -0.500639 Loss_G: 0.302908\n",
      "[161] Loss_D: -0.558398 Loss_G: 0.312744\n",
      "[162] Loss_D: -0.575603 Loss_G: 0.314550\n",
      "[163] Loss_D: -0.550237 Loss_G: 0.309324\n",
      "[164] Loss_D: -0.571282 Loss_G: 0.314260\n",
      "[165] Loss_D: -0.575549 Loss_G: 0.314315\n",
      "[166] Loss_D: -0.554299 Loss_G: 0.311655\n",
      "[167] Loss_D: -0.573701 Loss_G: 0.314009\n",
      "[168] Loss_D: -0.579364 Loss_G: 0.314344\n",
      "[169] Loss_D: -0.578415 Loss_G: 0.313756\n",
      "[170] Loss_D: -0.512868 Loss_G: 0.279717\n",
      "[171] Loss_D: -0.517664 Loss_G: 0.310169\n",
      "[172] Loss_D: -0.501102 Loss_G: 0.306510\n",
      "[173] Loss_D: -0.520335 Loss_G: 0.308591\n",
      "[174] Loss_D: -0.506621 Loss_G: 0.306209\n",
      "[175] Loss_D: -0.560082 Loss_G: 0.312293\n",
      "[176] Loss_D: -0.573979 Loss_G: 0.312925\n",
      "[177] Loss_D: -0.574497 Loss_G: 0.312282\n",
      "[178] Loss_D: -0.573245 Loss_G: 0.313175\n",
      "[179] Loss_D: -0.510790 Loss_G: 0.304421\n",
      "[180] Loss_D: -0.547007 Loss_G: 0.310101\n",
      "[181] Loss_D: -0.572231 Loss_G: 0.312242\n",
      "[182] Loss_D: -0.576050 Loss_G: 0.312366\n",
      "[183] Loss_D: -0.548367 Loss_G: 0.308999\n",
      "[184] Loss_D: -0.540454 Loss_G: 0.307087\n",
      "[185] Loss_D: -0.559029 Loss_G: 0.310771\n",
      "[186] Loss_D: -0.578741 Loss_G: 0.312418\n",
      "[187] Loss_D: -0.535416 Loss_G: 0.307877\n",
      "[188] Loss_D: -0.531612 Loss_G: 0.308477\n",
      "[189] Loss_D: -0.548944 Loss_G: 0.309678\n",
      "[190] Loss_D: -0.568406 Loss_G: 0.311147\n",
      "[191] Loss_D: -0.571649 Loss_G: 0.311616\n",
      "[192] Loss_D: -0.574338 Loss_G: 0.311671\n",
      "[193] Loss_D: -0.546290 Loss_G: 0.308525\n",
      "[194] Loss_D: -0.538580 Loss_G: 0.307502\n",
      "[195] Loss_D: -0.569181 Loss_G: 0.310664\n",
      "[196] Loss_D: -0.575843 Loss_G: 0.311370\n",
      "[197] Loss_D: -0.576666 Loss_G: 0.311019\n",
      "[198] Loss_D: -0.556271 Loss_G: 0.309692\n",
      "[199] Loss_D: -0.573245 Loss_G: 0.310440\n",
      "[200] Loss_D: -0.531705 Loss_G: 0.298743\n",
      "[201] Loss_D: -0.537796 Loss_G: 0.307925\n",
      "[202] Loss_D: -0.513898 Loss_G: 0.305796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203] Loss_D: -0.532845 Loss_G: 0.306547\n",
      "[204] Loss_D: -0.562114 Loss_G: 0.309147\n",
      "[205] Loss_D: -0.557387 Loss_G: 0.308387\n",
      "[206] Loss_D: -0.565073 Loss_G: 0.308824\n",
      "[207] Loss_D: -0.572145 Loss_G: 0.310221\n",
      "[208] Loss_D: -0.541764 Loss_G: 0.305478\n",
      "[209] Loss_D: -0.529575 Loss_G: 0.305992\n",
      "[210] Loss_D: -0.549564 Loss_G: 0.308102\n",
      "[211] Loss_D: -0.574523 Loss_G: 0.309357\n",
      "[212] Loss_D: -0.574366 Loss_G: 0.309302\n",
      "[213] Loss_D: -0.573257 Loss_G: 0.310290\n",
      "[214] Loss_D: -0.512423 Loss_G: 0.301764\n",
      "[215] Loss_D: -0.548378 Loss_G: 0.307304\n",
      "[216] Loss_D: -0.566297 Loss_G: 0.309023\n",
      "[217] Loss_D: -0.547959 Loss_G: 0.305705\n",
      "[218] Loss_D: -0.570325 Loss_G: 0.308987\n",
      "[219] Loss_D: -0.567950 Loss_G: 0.307810\n",
      "[220] Loss_D: -0.565271 Loss_G: 0.308081\n",
      "[221] Loss_D: -0.573392 Loss_G: 0.308791\n",
      "[222] Loss_D: -0.537231 Loss_G: 0.302119\n",
      "[223] Loss_D: -0.537389 Loss_G: 0.303579\n",
      "[224] Loss_D: -0.564736 Loss_G: 0.309065\n",
      "[225] Loss_D: -0.565575 Loss_G: 0.308421\n",
      "[226] Loss_D: -0.542077 Loss_G: 0.304937\n",
      "[227] Loss_D: -0.557768 Loss_G: 0.307182\n",
      "[228] Loss_D: -0.568286 Loss_G: 0.308468\n",
      "[229] Loss_D: -0.567369 Loss_G: 0.307847\n",
      "[230] Loss_D: -0.574840 Loss_G: 0.308869\n",
      "[231] Loss_D: -0.562561 Loss_G: 0.306426\n",
      "[232] Loss_D: -0.533601 Loss_G: 0.301555\n",
      "[233] Loss_D: -0.558322 Loss_G: 0.308183\n",
      "[234] Loss_D: -0.528056 Loss_G: 0.304274\n",
      "[235] Loss_D: -0.530928 Loss_G: 0.304872\n",
      "[236] Loss_D: -0.564851 Loss_G: 0.307583\n",
      "[237] Loss_D: -0.569236 Loss_G: 0.307962\n",
      "[238] Loss_D: -0.522125 Loss_G: 0.303710\n",
      "[239] Loss_D: -0.543540 Loss_G: 0.305455\n",
      "[240] Loss_D: -0.569299 Loss_G: 0.307917\n",
      "[241] Loss_D: -0.567838 Loss_G: 0.307512\n",
      "[242] Loss_D: -0.570632 Loss_G: 0.307781\n",
      "[243] Loss_D: -0.569903 Loss_G: 0.307272\n",
      "[244] Loss_D: -0.567940 Loss_G: 0.307505\n",
      "[245] Loss_D: -0.541009 Loss_G: 0.302990\n",
      "[246] Loss_D: -0.527373 Loss_G: 0.305282\n",
      "[247] Loss_D: -0.550624 Loss_G: 0.306226\n",
      "[248] Loss_D: -0.566943 Loss_G: 0.307415\n",
      "[249] Loss_D: -0.560056 Loss_G: 0.306332\n",
      "[250] Loss_D: -0.568406 Loss_G: 0.307365\n",
      "[251] Loss_D: -0.568640 Loss_G: 0.307131\n",
      "[252] Loss_D: -0.566341 Loss_G: 0.306917\n",
      "[253] Loss_D: -0.562514 Loss_G: 0.306210\n",
      "[254] Loss_D: -0.538483 Loss_G: 0.303021\n",
      "[255] Loss_D: -0.539801 Loss_G: 0.304345\n",
      "[256] Loss_D: -0.564595 Loss_G: 0.306448\n",
      "[257] Loss_D: -0.566659 Loss_G: 0.306369\n",
      "[258] Loss_D: -0.568128 Loss_G: 0.306615\n",
      "[259] Loss_D: -0.558770 Loss_G: 0.305680\n",
      "[260] Loss_D: -0.535479 Loss_G: 0.302337\n",
      "[261] Loss_D: -0.556521 Loss_G: 0.305773\n",
      "[262] Loss_D: -0.567224 Loss_G: 0.306250\n",
      "[263] Loss_D: -0.566185 Loss_G: 0.306360\n",
      "[264] Loss_D: -0.556978 Loss_G: 0.305112\n",
      "[265] Loss_D: -0.559065 Loss_G: 0.305222\n",
      "[266] Loss_D: -0.567904 Loss_G: 0.306554\n",
      "[267] Loss_D: -0.569895 Loss_G: 0.306191\n",
      "[268] Loss_D: -0.516235 Loss_G: 0.300215\n",
      "[269] Loss_D: -0.513408 Loss_G: 0.302825\n",
      "[270] Loss_D: -0.522154 Loss_G: 0.301237\n",
      "[271] Loss_D: -0.554065 Loss_G: 0.305064\n",
      "[272] Loss_D: -0.566176 Loss_G: 0.306216\n",
      "[273] Loss_D: -0.566559 Loss_G: 0.306312\n",
      "[274] Loss_D: -0.566280 Loss_G: 0.305850\n",
      "[275] Loss_D: -0.566861 Loss_G: 0.305785\n",
      "[276] Loss_D: -0.569958 Loss_G: 0.305901\n",
      "[277] Loss_D: -0.561487 Loss_G: 0.305929\n",
      "[278] Loss_D: -0.551888 Loss_G: 0.304345\n",
      "[279] Loss_D: -0.556185 Loss_G: 0.304414\n",
      "[280] Loss_D: -0.566764 Loss_G: 0.305356\n",
      "[281] Loss_D: -0.569269 Loss_G: 0.306212\n",
      "[282] Loss_D: -0.572246 Loss_G: 0.305810\n",
      "[283] Loss_D: -0.567041 Loss_G: 0.305156\n",
      "[284] Loss_D: -0.512602 Loss_G: 0.299696\n",
      "[285] Loss_D: -0.548038 Loss_G: 0.303881\n",
      "[286] Loss_D: -0.565573 Loss_G: 0.305318\n",
      "[287] Loss_D: -0.562529 Loss_G: 0.304301\n",
      "[288] Loss_D: -0.558646 Loss_G: 0.305271\n",
      "[289] Loss_D: -0.551615 Loss_G: 0.304317\n",
      "[290] Loss_D: -0.562150 Loss_G: 0.304555\n",
      "[291] Loss_D: -0.567028 Loss_G: 0.305611\n",
      "[292] Loss_D: -0.563564 Loss_G: 0.304543\n",
      "[293] Loss_D: -0.569287 Loss_G: 0.305635\n",
      "[294] Loss_D: -0.566485 Loss_G: 0.304408\n",
      "[295] Loss_D: -0.568155 Loss_G: 0.304907\n",
      "[296] Loss_D: -0.565534 Loss_G: 0.305516\n",
      "[297] Loss_D: -0.562987 Loss_G: 0.304188\n",
      "[298] Loss_D: -0.559930 Loss_G: 0.303948\n",
      "[299] Loss_D: -0.563446 Loss_G: 0.304340\n",
      "[300] Loss_D: -0.567771 Loss_G: 0.305216\n",
      "[301] Loss_D: -0.545906 Loss_G: 0.302610\n",
      "[302] Loss_D: -0.509998 Loss_G: 0.300357\n",
      "[303] Loss_D: -0.541004 Loss_G: 0.302712\n",
      "[304] Loss_D: -0.567682 Loss_G: 0.304882\n",
      "[305] Loss_D: -0.568075 Loss_G: 0.304619\n",
      "[306] Loss_D: -0.562013 Loss_G: 0.304130\n",
      "[307] Loss_D: -0.566576 Loss_G: 0.303748\n",
      "[308] Loss_D: -0.567727 Loss_G: 0.304977\n",
      "[309] Loss_D: -0.565021 Loss_G: 0.304083\n",
      "[310] Loss_D: -0.564782 Loss_G: 0.304681\n",
      "[311] Loss_D: -0.530413 Loss_G: 0.300719\n",
      "[312] Loss_D: -0.501845 Loss_G: 0.298630\n",
      "[313] Loss_D: -0.556735 Loss_G: 0.303890\n",
      "[314] Loss_D: -0.566069 Loss_G: 0.304219\n",
      "[315] Loss_D: -0.561909 Loss_G: 0.304000\n",
      "[316] Loss_D: -0.566347 Loss_G: 0.304032\n",
      "[317] Loss_D: -0.568484 Loss_G: 0.304450\n",
      "[318] Loss_D: -0.567346 Loss_G: 0.304272\n",
      "[319] Loss_D: -0.563839 Loss_G: 0.303808\n",
      "[320] Loss_D: -0.563057 Loss_G: 0.303981\n",
      "[321] Loss_D: -0.565170 Loss_G: 0.303652\n",
      "[322] Loss_D: -0.565358 Loss_G: 0.303719\n",
      "[323] Loss_D: -0.565572 Loss_G: 0.303808\n",
      "[324] Loss_D: -0.566215 Loss_G: 0.304165\n",
      "[325] Loss_D: -0.567996 Loss_G: 0.304184\n",
      "[326] Loss_D: -0.568979 Loss_G: 0.304110\n",
      "[327] Loss_D: -0.561534 Loss_G: 0.303398\n",
      "[328] Loss_D: -0.560335 Loss_G: 0.303401\n",
      "[329] Loss_D: -0.569225 Loss_G: 0.304472\n",
      "[330] Loss_D: -0.569269 Loss_G: 0.304312\n",
      "[331] Loss_D: -0.520045 Loss_G: 0.298346\n",
      "[332] Loss_D: -0.527162 Loss_G: 0.300331\n",
      "[333] Loss_D: -0.549079 Loss_G: 0.302670\n",
      "[334] Loss_D: -0.566145 Loss_G: 0.303888\n",
      "[335] Loss_D: -0.567627 Loss_G: 0.303632\n",
      "[336] Loss_D: -0.568532 Loss_G: 0.304245\n",
      "[337] Loss_D: -0.566657 Loss_G: 0.303584\n",
      "[338] Loss_D: -0.566381 Loss_G: 0.303941\n",
      "[339] Loss_D: -0.564719 Loss_G: 0.303534\n",
      "[340] Loss_D: -0.558391 Loss_G: 0.303196\n",
      "[341] Loss_D: -0.562977 Loss_G: 0.302339\n",
      "[342] Loss_D: -0.551320 Loss_G: 0.301804\n",
      "[343] Loss_D: -0.521181 Loss_G: 0.299822\n",
      "[344] Loss_D: -0.558641 Loss_G: 0.302647\n",
      "[345] Loss_D: -0.571896 Loss_G: 0.303759\n",
      "[346] Loss_D: -0.571419 Loss_G: 0.304132\n",
      "[347] Loss_D: -0.570684 Loss_G: 0.304076\n",
      "[348] Loss_D: -0.568472 Loss_G: 0.303029\n",
      "[349] Loss_D: -0.563611 Loss_G: 0.303661\n",
      "[350] Loss_D: -0.568526 Loss_G: 0.303763\n",
      "[351] Loss_D: -0.571145 Loss_G: 0.304111\n",
      "[352] Loss_D: -0.567846 Loss_G: 0.303167\n",
      "[353] Loss_D: -0.535376 Loss_G: 0.298845\n",
      "[354] Loss_D: -0.482165 Loss_G: 0.297934\n",
      "[355] Loss_D: -0.545635 Loss_G: 0.301420\n",
      "[356] Loss_D: -0.563507 Loss_G: 0.303289\n",
      "[357] Loss_D: -0.566731 Loss_G: 0.303246\n",
      "[358] Loss_D: -0.565238 Loss_G: 0.303495\n",
      "[359] Loss_D: -0.568406 Loss_G: 0.303451\n",
      "[360] Loss_D: -0.565993 Loss_G: 0.303348\n",
      "[361] Loss_D: -0.567597 Loss_G: 0.303349\n",
      "[362] Loss_D: -0.565194 Loss_G: 0.302749\n",
      "[363] Loss_D: -0.562185 Loss_G: 0.302774\n",
      "[364] Loss_D: -0.561966 Loss_G: 0.302406\n",
      "[365] Loss_D: -0.568228 Loss_G: 0.303723\n",
      "[366] Loss_D: -0.564053 Loss_G: 0.302817\n",
      "[367] Loss_D: -0.547702 Loss_G: 0.301481\n",
      "[368] Loss_D: -0.565738 Loss_G: 0.303067\n",
      "[369] Loss_D: -0.570409 Loss_G: 0.303369\n",
      "[370] Loss_D: -0.569957 Loss_G: 0.303741\n",
      "[371] Loss_D: -0.564253 Loss_G: 0.302458\n",
      "[372] Loss_D: -0.565260 Loss_G: 0.302488\n",
      "[373] Loss_D: -0.559259 Loss_G: 0.302312\n",
      "[374] Loss_D: -0.566726 Loss_G: 0.302834\n",
      "[375] Loss_D: -0.567671 Loss_G: 0.303061\n",
      "[376] Loss_D: -0.547093 Loss_G: 0.300417\n",
      "[377] Loss_D: -0.472755 Loss_G: 0.295936\n",
      "[378] Loss_D: -0.529700 Loss_G: 0.299554\n",
      "[379] Loss_D: -0.560833 Loss_G: 0.301934\n",
      "[380] Loss_D: -0.564779 Loss_G: 0.302247\n",
      "[381] Loss_D: -0.563780 Loss_G: 0.302972\n",
      "[382] Loss_D: -0.564527 Loss_G: 0.301885\n",
      "[383] Loss_D: -0.564910 Loss_G: 0.303029\n",
      "[384] Loss_D: -0.569877 Loss_G: 0.303268\n",
      "[385] Loss_D: -0.567701 Loss_G: 0.303344\n",
      "[386] Loss_D: -0.568717 Loss_G: 0.302535\n",
      "[387] Loss_D: -0.566753 Loss_G: 0.301670\n",
      "[388] Loss_D: -0.563398 Loss_G: 0.303313\n",
      "[389] Loss_D: -0.547807 Loss_G: 0.300570\n",
      "[390] Loss_D: -0.564541 Loss_G: 0.302402\n",
      "[391] Loss_D: -0.544149 Loss_G: 0.299168\n",
      "[392] Loss_D: -0.498233 Loss_G: 0.298209\n",
      "[393] Loss_D: -0.547070 Loss_G: 0.300913\n",
      "[394] Loss_D: -0.565116 Loss_G: 0.301998\n",
      "[395] Loss_D: -0.565214 Loss_G: 0.302407\n",
      "[396] Loss_D: -0.568891 Loss_G: 0.303076\n",
      "[397] Loss_D: -0.567527 Loss_G: 0.303222\n",
      "[398] Loss_D: -0.568288 Loss_G: 0.302345\n",
      "[399] Loss_D: -0.566363 Loss_G: 0.302056\n",
      "[400] Loss_D: -0.563333 Loss_G: 0.300617\n",
      "[401] Loss_D: -0.548635 Loss_G: 0.302539\n",
      "[402] Loss_D: -0.562156 Loss_G: 0.302530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403] Loss_D: -0.564969 Loss_G: 0.302514\n",
      "[404] Loss_D: -0.566998 Loss_G: 0.302402\n",
      "[405] Loss_D: -0.563701 Loss_G: 0.302451\n",
      "[406] Loss_D: -0.559555 Loss_G: 0.302334\n",
      "[407] Loss_D: -0.568772 Loss_G: 0.302460\n",
      "[408] Loss_D: -0.568015 Loss_G: 0.302783\n",
      "[409] Loss_D: -0.566685 Loss_G: 0.301839\n",
      "[410] Loss_D: -0.562176 Loss_G: 0.300649\n",
      "[411] Loss_D: -0.559199 Loss_G: 0.302243\n",
      "[412] Loss_D: -0.557139 Loss_G: 0.301514\n",
      "[413] Loss_D: -0.565177 Loss_G: 0.301881\n",
      "[414] Loss_D: -0.568277 Loss_G: 0.302264\n",
      "[415] Loss_D: -0.564235 Loss_G: 0.302133\n",
      "[416] Loss_D: -0.565954 Loss_G: 0.302069\n",
      "[417] Loss_D: -0.563251 Loss_G: 0.301391\n",
      "[418] Loss_D: -0.541051 Loss_G: 0.299782\n",
      "[419] Loss_D: -0.479854 Loss_G: 0.295384\n",
      "[420] Loss_D: -0.534013 Loss_G: 0.299754\n",
      "[421] Loss_D: -0.562725 Loss_G: 0.301339\n",
      "[422] Loss_D: -0.564756 Loss_G: 0.301774\n",
      "[423] Loss_D: -0.564839 Loss_G: 0.302003\n",
      "[424] Loss_D: -0.566469 Loss_G: 0.301976\n",
      "[425] Loss_D: -0.565804 Loss_G: 0.302281\n",
      "[426] Loss_D: -0.565970 Loss_G: 0.302093\n",
      "[427] Loss_D: -0.567178 Loss_G: 0.302102\n",
      "[428] Loss_D: -0.567682 Loss_G: 0.302009\n",
      "[429] Loss_D: -0.566336 Loss_G: 0.301944\n",
      "[430] Loss_D: -0.568174 Loss_G: 0.302200\n",
      "[431] Loss_D: -0.567525 Loss_G: 0.302424\n",
      "[432] Loss_D: -0.563119 Loss_G: 0.301813\n",
      "[433] Loss_D: -0.563923 Loss_G: 0.301238\n",
      "[434] Loss_D: -0.562701 Loss_G: 0.301325\n",
      "[435] Loss_D: -0.562594 Loss_G: 0.301874\n",
      "[436] Loss_D: -0.570886 Loss_G: 0.302373\n",
      "[437] Loss_D: -0.566025 Loss_G: 0.301739\n",
      "[438] Loss_D: -0.567373 Loss_G: 0.302350\n",
      "[439] Loss_D: -0.567811 Loss_G: 0.302071\n",
      "[440] Loss_D: -0.567424 Loss_G: 0.301259\n",
      "[441] Loss_D: -0.540897 Loss_G: 0.297916\n",
      "[442] Loss_D: -0.476479 Loss_G: 0.295181\n",
      "[443] Loss_D: -0.523722 Loss_G: 0.298735\n",
      "[444] Loss_D: -0.557052 Loss_G: 0.300489\n",
      "[445] Loss_D: -0.560713 Loss_G: 0.301497\n",
      "[446] Loss_D: -0.564058 Loss_G: 0.301247\n",
      "[447] Loss_D: -0.564270 Loss_G: 0.301628\n",
      "[448] Loss_D: -0.562383 Loss_G: 0.301343\n",
      "[449] Loss_D: -0.563981 Loss_G: 0.301132\n",
      "[450] Loss_D: -0.565392 Loss_G: 0.300540\n",
      "[451] Loss_D: -0.559188 Loss_G: 0.301394\n",
      "[452] Loss_D: -0.560663 Loss_G: 0.300998\n",
      "[453] Loss_D: -0.557951 Loss_G: 0.300417\n",
      "[454] Loss_D: -0.556878 Loss_G: 0.300371\n",
      "[455] Loss_D: -0.561333 Loss_G: 0.301454\n",
      "[456] Loss_D: -0.564878 Loss_G: 0.301601\n",
      "[457] Loss_D: -0.559175 Loss_G: 0.300683\n",
      "[458] Loss_D: -0.564713 Loss_G: 0.301483\n",
      "[459] Loss_D: -0.562944 Loss_G: 0.300341\n",
      "[460] Loss_D: -0.560735 Loss_G: 0.301252\n",
      "[461] Loss_D: -0.527563 Loss_G: 0.297209\n",
      "[462] Loss_D: -0.555877 Loss_G: 0.300494\n",
      "[463] Loss_D: -0.568271 Loss_G: 0.301360\n",
      "[464] Loss_D: -0.566156 Loss_G: 0.301069\n",
      "[465] Loss_D: -0.565944 Loss_G: 0.301484\n",
      "[466] Loss_D: -0.567865 Loss_G: 0.301360\n",
      "[467] Loss_D: -0.565615 Loss_G: 0.301244\n",
      "[468] Loss_D: -0.565613 Loss_G: 0.301010\n",
      "[469] Loss_D: -0.566441 Loss_G: 0.301411\n",
      "[470] Loss_D: -0.551761 Loss_G: 0.299522\n",
      "[471] Loss_D: -0.546253 Loss_G: 0.298920\n",
      "[472] Loss_D: -0.566059 Loss_G: 0.300982\n",
      "[473] Loss_D: -0.565800 Loss_G: 0.300608\n",
      "[474] Loss_D: -0.563722 Loss_G: 0.300580\n",
      "[475] Loss_D: -0.561921 Loss_G: 0.300715\n",
      "[476] Loss_D: -0.565990 Loss_G: 0.300327\n",
      "[477] Loss_D: -0.547725 Loss_G: 0.299754\n",
      "[478] Loss_D: -0.558169 Loss_G: 0.299981\n",
      "[479] Loss_D: -0.561989 Loss_G: 0.300684\n",
      "[480] Loss_D: -0.560406 Loss_G: 0.300812\n",
      "[481] Loss_D: -0.563998 Loss_G: 0.300736\n",
      "[482] Loss_D: -0.563938 Loss_G: 0.300336\n",
      "[483] Loss_D: -0.562895 Loss_G: 0.301082\n",
      "[484] Loss_D: -0.562947 Loss_G: 0.301028\n",
      "[485] Loss_D: -0.563787 Loss_G: 0.300152\n",
      "[486] Loss_D: -0.566204 Loss_G: 0.301409\n",
      "[487] Loss_D: -0.563662 Loss_G: 0.300571\n",
      "[488] Loss_D: -0.567439 Loss_G: 0.301291\n",
      "[489] Loss_D: -0.560776 Loss_G: 0.300407\n",
      "[490] Loss_D: -0.563396 Loss_G: 0.300955\n",
      "[491] Loss_D: -0.567299 Loss_G: 0.301362\n",
      "[492] Loss_D: -0.568739 Loss_G: 0.300870\n",
      "[493] Loss_D: -0.566832 Loss_G: 0.301033\n",
      "[494] Loss_D: -0.561947 Loss_G: 0.299854\n",
      "[495] Loss_D: -0.563801 Loss_G: 0.300737\n",
      "[496] Loss_D: -0.564598 Loss_G: 0.300968\n",
      "[497] Loss_D: -0.565798 Loss_G: 0.300839\n",
      "[498] Loss_D: -0.564365 Loss_G: 0.300808\n",
      "[499] Loss_D: -0.566041 Loss_G: 0.301023\n",
      "[500] Loss_D: -0.561193 Loss_G: 0.300407\n",
      "[501] Loss_D: -0.551869 Loss_G: 0.299413\n",
      "[502] Loss_D: -0.564503 Loss_G: 0.300357\n",
      "[503] Loss_D: -0.565988 Loss_G: 0.300995\n",
      "[504] Loss_D: -0.565196 Loss_G: 0.300262\n",
      "[505] Loss_D: -0.560283 Loss_G: 0.300113\n",
      "[506] Loss_D: -0.546607 Loss_G: 0.299037\n",
      "[507] Loss_D: -0.554448 Loss_G: 0.299612\n",
      "[508] Loss_D: -0.568225 Loss_G: 0.300740\n",
      "[509] Loss_D: -0.567008 Loss_G: 0.300336\n",
      "[510] Loss_D: -0.556255 Loss_G: 0.299637\n",
      "[511] Loss_D: -0.558158 Loss_G: 0.300037\n",
      "[512] Loss_D: -0.562499 Loss_G: 0.300028\n",
      "[513] Loss_D: -0.558872 Loss_G: 0.299803\n",
      "[514] Loss_D: -0.550250 Loss_G: 0.298593\n",
      "[515] Loss_D: -0.552570 Loss_G: 0.299093\n",
      "[516] Loss_D: -0.567814 Loss_G: 0.300979\n",
      "[517] Loss_D: -0.569080 Loss_G: 0.300708\n",
      "[518] Loss_D: -0.564140 Loss_G: 0.300490\n",
      "[519] Loss_D: -0.564193 Loss_G: 0.300364\n",
      "[520] Loss_D: -0.565877 Loss_G: 0.300679\n",
      "[521] Loss_D: -0.565786 Loss_G: 0.299915\n",
      "[522] Loss_D: -0.566411 Loss_G: 0.300699\n",
      "[523] Loss_D: -0.555322 Loss_G: 0.299355\n",
      "[524] Loss_D: -0.558108 Loss_G: 0.299798\n",
      "[525] Loss_D: -0.566477 Loss_G: 0.300472\n",
      "[526] Loss_D: -0.567850 Loss_G: 0.300665\n",
      "[527] Loss_D: -0.564648 Loss_G: 0.300523\n",
      "[528] Loss_D: -0.564398 Loss_G: 0.299796\n",
      "[529] Loss_D: -0.565229 Loss_G: 0.300630\n",
      "[530] Loss_D: -0.563679 Loss_G: 0.299594\n",
      "[531] Loss_D: -0.563690 Loss_G: 0.299993\n",
      "[532] Loss_D: -0.567005 Loss_G: 0.300151\n",
      "[533] Loss_D: -0.518032 Loss_G: 0.293760\n",
      "[534] Loss_D: -0.451333 Loss_G: 0.292516\n",
      "[535] Loss_D: -0.508368 Loss_G: 0.296011\n",
      "[536] Loss_D: -0.550802 Loss_G: 0.298858\n",
      "[537] Loss_D: -0.557666 Loss_G: 0.299477\n",
      "[538] Loss_D: -0.562942 Loss_G: 0.299814\n",
      "[539] Loss_D: -0.563821 Loss_G: 0.299978\n",
      "[540] Loss_D: -0.564459 Loss_G: 0.300645\n",
      "[541] Loss_D: -0.561866 Loss_G: 0.299538\n",
      "[542] Loss_D: -0.563186 Loss_G: 0.300321\n",
      "[543] Loss_D: -0.562245 Loss_G: 0.300089\n",
      "[544] Loss_D: -0.565539 Loss_G: 0.301004\n",
      "[545] Loss_D: -0.568727 Loss_G: 0.300379\n",
      "[546] Loss_D: -0.567828 Loss_G: 0.300288\n",
      "[547] Loss_D: -0.565928 Loss_G: 0.300845\n",
      "[548] Loss_D: -0.566662 Loss_G: 0.300195\n",
      "[549] Loss_D: -0.566743 Loss_G: 0.300449\n",
      "[550] Loss_D: -0.565727 Loss_G: 0.300690\n",
      "[551] Loss_D: -0.569428 Loss_G: 0.301241\n",
      "[552] Loss_D: -0.567663 Loss_G: 0.300268\n",
      "[553] Loss_D: -0.563736 Loss_G: 0.300483\n",
      "[554] Loss_D: -0.556961 Loss_G: 0.299249\n",
      "[555] Loss_D: -0.564611 Loss_G: 0.299942\n",
      "[556] Loss_D: -0.566966 Loss_G: 0.300299\n",
      "[557] Loss_D: -0.562575 Loss_G: 0.300253\n",
      "[558] Loss_D: -0.562536 Loss_G: 0.299389\n",
      "[559] Loss_D: -0.561385 Loss_G: 0.300065\n",
      "[560] Loss_D: -0.552342 Loss_G: 0.298823\n",
      "[561] Loss_D: -0.561356 Loss_G: 0.300085\n",
      "[562] Loss_D: -0.491069 Loss_G: 0.292898\n",
      "[563] Loss_D: -0.494884 Loss_G: 0.294494\n",
      "[564] Loss_D: -0.546114 Loss_G: 0.298446\n",
      "[565] Loss_D: -0.557568 Loss_G: 0.299544\n",
      "[566] Loss_D: -0.562307 Loss_G: 0.299921\n",
      "[567] Loss_D: -0.564889 Loss_G: 0.299938\n",
      "[568] Loss_D: -0.565930 Loss_G: 0.300692\n",
      "[569] Loss_D: -0.567898 Loss_G: 0.300498\n",
      "[570] Loss_D: -0.561360 Loss_G: 0.299975\n",
      "[571] Loss_D: -0.569083 Loss_G: 0.300574\n",
      "[572] Loss_D: -0.569258 Loss_G: 0.300249\n",
      "[573] Loss_D: -0.564321 Loss_G: 0.299913\n",
      "[574] Loss_D: -0.566290 Loss_G: 0.299985\n",
      "[575] Loss_D: -0.565828 Loss_G: 0.300250\n",
      "[576] Loss_D: -0.563182 Loss_G: 0.300130\n",
      "[577] Loss_D: -0.565314 Loss_G: 0.300334\n",
      "[578] Loss_D: -0.566120 Loss_G: 0.300291\n",
      "[579] Loss_D: -0.568899 Loss_G: 0.300714\n",
      "[580] Loss_D: -0.569963 Loss_G: 0.300782\n",
      "[581] Loss_D: -0.559179 Loss_G: 0.299673\n",
      "[582] Loss_D: -0.551845 Loss_G: 0.298353\n",
      "[583] Loss_D: -0.539904 Loss_G: 0.297210\n",
      "[584] Loss_D: -0.568022 Loss_G: 0.300629\n",
      "[585] Loss_D: -0.570028 Loss_G: 0.300484\n",
      "[586] Loss_D: -0.521262 Loss_G: 0.289801\n",
      "[587] Loss_D: -0.415470 Loss_G: 0.283395\n",
      "[588] Loss_D: -0.448452 Loss_G: 0.290206\n",
      "[589] Loss_D: -0.495182 Loss_G: 0.297171\n",
      "[590] Loss_D: -0.505663 Loss_G: 0.295732\n",
      "[591] Loss_D: -0.520205 Loss_G: 0.297362\n",
      "[592] Loss_D: -0.543140 Loss_G: 0.299234\n",
      "[593] Loss_D: -0.568385 Loss_G: 0.301521\n",
      "[594] Loss_D: -0.563456 Loss_G: 0.300052\n",
      "[595] Loss_D: -0.560627 Loss_G: 0.300005\n",
      "[596] Loss_D: -0.541606 Loss_G: 0.295769\n",
      "[597] Loss_D: -0.585564 Loss_G: 0.307750\n",
      "[598] Loss_D: -0.585913 Loss_G: 0.305786\n",
      "[599] Loss_D: -0.484324 Loss_G: 0.293752\n",
      "[600] Loss_D: -0.460612 Loss_G: 0.285560\n",
      "[601] Loss_D: -0.477792 Loss_G: 0.298866\n",
      "[602] Loss_D: -0.476412 Loss_G: 0.295505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[603] Loss_D: -0.523583 Loss_G: 0.294242\n",
      "[604] Loss_D: -0.518017 Loss_G: 0.296843\n",
      "[605] Loss_D: -0.531540 Loss_G: 0.302576\n",
      "[606] Loss_D: -0.518860 Loss_G: 0.299216\n",
      "[607] Loss_D: -0.488504 Loss_G: 0.289992\n",
      "[608] Loss_D: -0.549689 Loss_G: 0.303743\n",
      "[609] Loss_D: -0.482146 Loss_G: 0.290804\n",
      "[610] Loss_D: -0.465382 Loss_G: 0.294905\n",
      "[611] Loss_D: -0.500675 Loss_G: 0.300100\n",
      "[612] Loss_D: -0.556131 Loss_G: 0.303886\n",
      "[613] Loss_D: -0.536050 Loss_G: 0.298050\n",
      "[614] Loss_D: -0.525152 Loss_G: 0.300779\n",
      "[615] Loss_D: -0.459203 Loss_G: 0.293190\n",
      "[616] Loss_D: -0.537902 Loss_G: 0.301811\n",
      "[617] Loss_D: -0.570751 Loss_G: 0.304247\n",
      "[618] Loss_D: -0.521238 Loss_G: 0.286481\n",
      "[619] Loss_D: -0.515763 Loss_G: 0.300177\n",
      "[620] Loss_D: -0.537702 Loss_G: 0.300940\n",
      "[621] Loss_D: -0.570416 Loss_G: 0.303509\n",
      "[622] Loss_D: -0.573131 Loss_G: 0.303709\n",
      "[623] Loss_D: -0.576743 Loss_G: 0.304220\n",
      "[624] Loss_D: -0.503458 Loss_G: 0.296063\n",
      "[625] Loss_D: -0.567501 Loss_G: 0.303196\n",
      "[626] Loss_D: -0.576276 Loss_G: 0.303477\n",
      "[627] Loss_D: -0.513847 Loss_G: 0.288719\n",
      "[628] Loss_D: -0.520542 Loss_G: 0.290835\n",
      "[629] Loss_D: -0.512342 Loss_G: 0.296069\n",
      "[630] Loss_D: -0.538087 Loss_G: 0.298284\n",
      "[631] Loss_D: -0.569646 Loss_G: 0.302752\n",
      "[632] Loss_D: -0.569927 Loss_G: 0.302394\n",
      "[633] Loss_D: -0.577355 Loss_G: 0.303267\n",
      "[634] Loss_D: -0.581881 Loss_G: 0.303835\n",
      "[635] Loss_D: -0.581810 Loss_G: 0.303945\n",
      "[636] Loss_D: -0.582321 Loss_G: 0.303755\n",
      "[637] Loss_D: -0.575462 Loss_G: 0.302544\n",
      "[638] Loss_D: -0.409398 Loss_G: 0.280078\n",
      "[639] Loss_D: -0.457342 Loss_G: 0.292657\n",
      "[640] Loss_D: -0.484974 Loss_G: 0.294501\n",
      "[641] Loss_D: -0.547594 Loss_G: 0.300034\n",
      "[642] Loss_D: -0.563683 Loss_G: 0.301521\n",
      "[643] Loss_D: -0.569918 Loss_G: 0.301593\n",
      "[644] Loss_D: -0.496652 Loss_G: 0.251439\n",
      "[645] Loss_D: -0.481611 Loss_G: 0.293519\n",
      "[646] Loss_D: -0.500589 Loss_G: 0.296559\n",
      "[647] Loss_D: -0.542213 Loss_G: 0.299633\n",
      "[648] Loss_D: -0.568549 Loss_G: 0.302031\n",
      "[649] Loss_D: -0.570801 Loss_G: 0.302563\n",
      "[650] Loss_D: -0.577220 Loss_G: 0.303165\n",
      "[651] Loss_D: -0.577809 Loss_G: 0.303060\n",
      "[652] Loss_D: -0.468604 Loss_G: 0.263125\n",
      "[653] Loss_D: -0.486346 Loss_G: 0.294923\n",
      "[654] Loss_D: -0.485140 Loss_G: 0.293779\n",
      "[655] Loss_D: -0.551038 Loss_G: 0.300494\n",
      "[656] Loss_D: -0.550400 Loss_G: 0.299581\n",
      "[657] Loss_D: -0.567709 Loss_G: 0.301678\n",
      "[658] Loss_D: -0.573522 Loss_G: 0.302585\n",
      "[659] Loss_D: -0.574230 Loss_G: 0.302228\n",
      "[660] Loss_D: -0.578155 Loss_G: 0.302447\n",
      "[661] Loss_D: -0.520892 Loss_G: 0.287332\n",
      "[662] Loss_D: -0.563890 Loss_G: 0.301298\n",
      "[663] Loss_D: -0.524009 Loss_G: 0.291310\n",
      "[664] Loss_D: -0.484222 Loss_G: 0.290044\n",
      "[665] Loss_D: -0.535443 Loss_G: 0.298328\n",
      "[666] Loss_D: -0.552690 Loss_G: 0.299570\n",
      "[667] Loss_D: -0.572624 Loss_G: 0.302437\n",
      "[668] Loss_D: -0.575799 Loss_G: 0.302579\n",
      "[669] Loss_D: -0.575261 Loss_G: 0.302357\n",
      "[670] Loss_D: -0.541715 Loss_G: 0.266752\n",
      "[671] Loss_D: -0.497003 Loss_G: 0.295283\n",
      "[672] Loss_D: -0.534391 Loss_G: 0.298311\n",
      "[673] Loss_D: -0.514146 Loss_G: 0.295763\n",
      "[674] Loss_D: -0.547556 Loss_G: 0.299202\n",
      "[675] Loss_D: -0.570276 Loss_G: 0.301742\n",
      "[676] Loss_D: -0.571901 Loss_G: 0.301581\n",
      "[677] Loss_D: -0.572382 Loss_G: 0.301514\n",
      "[678] Loss_D: -0.534186 Loss_G: 0.296648\n",
      "[679] Loss_D: -0.523124 Loss_G: 0.297133\n",
      "[680] Loss_D: -0.570438 Loss_G: 0.301237\n",
      "[681] Loss_D: -0.574689 Loss_G: 0.301326\n",
      "[682] Loss_D: -0.571230 Loss_G: 0.301291\n",
      "[683] Loss_D: -0.521001 Loss_G: 0.295874\n",
      "[684] Loss_D: -0.538386 Loss_G: 0.297800\n",
      "[685] Loss_D: -0.572238 Loss_G: 0.300804\n",
      "[686] Loss_D: -0.573368 Loss_G: 0.301142\n",
      "[687] Loss_D: -0.574172 Loss_G: 0.301440\n",
      "[688] Loss_D: -0.578167 Loss_G: 0.301483\n",
      "[689] Loss_D: -0.520275 Loss_G: 0.292156\n",
      "[690] Loss_D: -0.452900 Loss_G: 0.286861\n",
      "[691] Loss_D: -0.519866 Loss_G: 0.296822\n",
      "[692] Loss_D: -0.543012 Loss_G: 0.298448\n",
      "[693] Loss_D: -0.565359 Loss_G: 0.300417\n",
      "[694] Loss_D: -0.568834 Loss_G: 0.300691\n",
      "[695] Loss_D: -0.564595 Loss_G: 0.300072\n",
      "[696] Loss_D: -0.568714 Loss_G: 0.300448\n",
      "[697] Loss_D: -0.571685 Loss_G: 0.300814\n",
      "[698] Loss_D: -0.530515 Loss_G: 0.287375\n",
      "[699] Loss_D: -0.463401 Loss_G: 0.289476\n",
      "[700] Loss_D: -0.551899 Loss_G: 0.299633\n",
      "[701] Loss_D: -0.568221 Loss_G: 0.300325\n",
      "[702] Loss_D: -0.564509 Loss_G: 0.300322\n",
      "[703] Loss_D: -0.532089 Loss_G: 0.296115\n",
      "[704] Loss_D: -0.527402 Loss_G: 0.294741\n",
      "[705] Loss_D: -0.539819 Loss_G: 0.296455\n",
      "[706] Loss_D: -0.545729 Loss_G: 0.297669\n",
      "[707] Loss_D: -0.568197 Loss_G: 0.300659\n",
      "[708] Loss_D: -0.570744 Loss_G: 0.300526\n",
      "[709] Loss_D: -0.574235 Loss_G: 0.300954\n",
      "[710] Loss_D: -0.573519 Loss_G: 0.300909\n",
      "[711] Loss_D: -0.565031 Loss_G: 0.299801\n",
      "[712] Loss_D: -0.554100 Loss_G: 0.296874\n",
      "[713] Loss_D: -0.459590 Loss_G: 0.291010\n",
      "[714] Loss_D: -0.506958 Loss_G: 0.292879\n",
      "[715] Loss_D: -0.548953 Loss_G: 0.298673\n",
      "[716] Loss_D: -0.569200 Loss_G: 0.299962\n",
      "[717] Loss_D: -0.533371 Loss_G: 0.293041\n",
      "[718] Loss_D: -0.557000 Loss_G: 0.298909\n",
      "[719] Loss_D: -0.568451 Loss_G: 0.300319\n",
      "[720] Loss_D: -0.570808 Loss_G: 0.300658\n",
      "[721] Loss_D: -0.573647 Loss_G: 0.300734\n",
      "[722] Loss_D: -0.576674 Loss_G: 0.301219\n",
      "[723] Loss_D: -0.545894 Loss_G: 0.296723\n",
      "[724] Loss_D: -0.479851 Loss_G: 0.291014\n",
      "[725] Loss_D: -0.554373 Loss_G: 0.298277\n",
      "[726] Loss_D: -0.569512 Loss_G: 0.300146\n",
      "[727] Loss_D: -0.573362 Loss_G: 0.300544\n",
      "[728] Loss_D: -0.572031 Loss_G: 0.300396\n",
      "[729] Loss_D: -0.566278 Loss_G: 0.299391\n",
      "[730] Loss_D: -0.529653 Loss_G: 0.295120\n",
      "[731] Loss_D: -0.565931 Loss_G: 0.299649\n",
      "[732] Loss_D: -0.573533 Loss_G: 0.300314\n",
      "[733] Loss_D: -0.575737 Loss_G: 0.300937\n",
      "[734] Loss_D: -0.571521 Loss_G: 0.300213\n",
      "[735] Loss_D: -0.506612 Loss_G: 0.288782\n",
      "[736] Loss_D: -0.520332 Loss_G: 0.294541\n",
      "[737] Loss_D: -0.565722 Loss_G: 0.299502\n",
      "[738] Loss_D: -0.571614 Loss_G: 0.299902\n",
      "[739] Loss_D: -0.571730 Loss_G: 0.300022\n",
      "[740] Loss_D: -0.572107 Loss_G: 0.300184\n",
      "[741] Loss_D: -0.571954 Loss_G: 0.299915\n",
      "[742] Loss_D: -0.573405 Loss_G: 0.300355\n",
      "[743] Loss_D: -0.572876 Loss_G: 0.299760\n",
      "[744] Loss_D: -0.573858 Loss_G: 0.300295\n",
      "[745] Loss_D: -0.569423 Loss_G: 0.299690\n",
      "[746] Loss_D: -0.505869 Loss_G: 0.291671\n",
      "[747] Loss_D: -0.424020 Loss_G: 0.288240\n",
      "[748] Loss_D: -0.464869 Loss_G: 0.290590\n",
      "[749] Loss_D: -0.521981 Loss_G: 0.295562\n",
      "[750] Loss_D: -0.547888 Loss_G: 0.297745\n",
      "[751] Loss_D: -0.553935 Loss_G: 0.298430\n",
      "[752] Loss_D: -0.561813 Loss_G: 0.298637\n",
      "[753] Loss_D: -0.564410 Loss_G: 0.299015\n",
      "[754] Loss_D: -0.564102 Loss_G: 0.299038\n",
      "[755] Loss_D: -0.559836 Loss_G: 0.298673\n",
      "[756] Loss_D: -0.483973 Loss_G: 0.286690\n",
      "[757] Loss_D: -0.496861 Loss_G: 0.293076\n",
      "[758] Loss_D: -0.548743 Loss_G: 0.297537\n",
      "[759] Loss_D: -0.562353 Loss_G: 0.298842\n",
      "[760] Loss_D: -0.566144 Loss_G: 0.299441\n",
      "[761] Loss_D: -0.565604 Loss_G: 0.299047\n",
      "[762] Loss_D: -0.547263 Loss_G: 0.295985\n",
      "[763] Loss_D: -0.560116 Loss_G: 0.298766\n",
      "[764] Loss_D: -0.572187 Loss_G: 0.299884\n",
      "[765] Loss_D: -0.570480 Loss_G: 0.299893\n",
      "[766] Loss_D: -0.563040 Loss_G: 0.297877\n",
      "[767] Loss_D: -0.524757 Loss_G: 0.291096\n",
      "[768] Loss_D: -0.563525 Loss_G: 0.299415\n",
      "[769] Loss_D: -0.570391 Loss_G: 0.300095\n",
      "[770] Loss_D: -0.568230 Loss_G: 0.299754\n",
      "[771] Loss_D: -0.570050 Loss_G: 0.299744\n",
      "[772] Loss_D: -0.566741 Loss_G: 0.299309\n",
      "[773] Loss_D: -0.571252 Loss_G: 0.300135\n",
      "[774] Loss_D: -0.500303 Loss_G: 0.292301\n",
      "[775] Loss_D: -0.523852 Loss_G: 0.295158\n",
      "[776] Loss_D: -0.564703 Loss_G: 0.299170\n",
      "[777] Loss_D: -0.567172 Loss_G: 0.299159\n",
      "[778] Loss_D: -0.567169 Loss_G: 0.299799\n",
      "[779] Loss_D: -0.570297 Loss_G: 0.299804\n",
      "[780] Loss_D: -0.570066 Loss_G: 0.299934\n",
      "[781] Loss_D: -0.495495 Loss_G: 0.291033\n",
      "[782] Loss_D: -0.525396 Loss_G: 0.294363\n",
      "[783] Loss_D: -0.564604 Loss_G: 0.298890\n",
      "[784] Loss_D: -0.569332 Loss_G: 0.299409\n",
      "[785] Loss_D: -0.564821 Loss_G: 0.298795\n",
      "[786] Loss_D: -0.558155 Loss_G: 0.298230\n",
      "[787] Loss_D: -0.562366 Loss_G: 0.298241\n",
      "[788] Loss_D: -0.467350 Loss_G: 0.289965\n",
      "[789] Loss_D: -0.503811 Loss_G: 0.292986\n",
      "[790] Loss_D: -0.552119 Loss_G: 0.297075\n",
      "[791] Loss_D: -0.563078 Loss_G: 0.298290\n",
      "[792] Loss_D: -0.564262 Loss_G: 0.298674\n",
      "[793] Loss_D: -0.563415 Loss_G: 0.298702\n",
      "[794] Loss_D: -0.565815 Loss_G: 0.299024\n",
      "[795] Loss_D: -0.566444 Loss_G: 0.299383\n",
      "[796] Loss_D: -0.566991 Loss_G: 0.299211\n",
      "[797] Loss_D: -0.569785 Loss_G: 0.299487\n",
      "[798] Loss_D: -0.566734 Loss_G: 0.299026\n",
      "[799] Loss_D: -0.570979 Loss_G: 0.299876\n",
      "[800] Loss_D: -0.571010 Loss_G: 0.299284\n",
      "[801] Loss_D: -0.569002 Loss_G: 0.299550\n",
      "[802] Loss_D: -0.547750 Loss_G: 0.296031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[803] Loss_D: -0.535414 Loss_G: 0.294864\n",
      "[804] Loss_D: -0.559198 Loss_G: 0.297859\n",
      "[805] Loss_D: -0.569866 Loss_G: 0.299319\n",
      "[806] Loss_D: -0.566532 Loss_G: 0.299227\n",
      "[807] Loss_D: -0.567043 Loss_G: 0.298989\n",
      "[808] Loss_D: -0.478172 Loss_G: 0.286440\n",
      "[809] Loss_D: -0.465366 Loss_G: 0.290316\n",
      "[810] Loss_D: -0.523920 Loss_G: 0.294579\n",
      "[811] Loss_D: -0.555985 Loss_G: 0.297670\n",
      "[812] Loss_D: -0.561716 Loss_G: 0.298281\n",
      "[813] Loss_D: -0.567844 Loss_G: 0.298753\n",
      "[814] Loss_D: -0.569212 Loss_G: 0.299023\n",
      "[815] Loss_D: -0.567822 Loss_G: 0.298697\n",
      "[816] Loss_D: -0.562952 Loss_G: 0.298055\n",
      "[817] Loss_D: -0.529917 Loss_G: 0.294522\n",
      "[818] Loss_D: -0.562748 Loss_G: 0.298789\n",
      "[819] Loss_D: -0.566847 Loss_G: 0.299590\n",
      "[820] Loss_D: -0.572021 Loss_G: 0.299742\n",
      "[821] Loss_D: -0.571296 Loss_G: 0.299558\n",
      "[822] Loss_D: -0.571336 Loss_G: 0.299114\n",
      "[823] Loss_D: -0.556839 Loss_G: 0.297332\n",
      "[824] Loss_D: -0.556138 Loss_G: 0.298197\n",
      "[825] Loss_D: -0.570224 Loss_G: 0.299734\n",
      "[826] Loss_D: -0.569704 Loss_G: 0.299358\n",
      "[827] Loss_D: -0.574817 Loss_G: 0.299467\n",
      "[828] Loss_D: -0.567413 Loss_G: 0.298401\n",
      "[829] Loss_D: -0.490610 Loss_G: 0.290371\n",
      "[830] Loss_D: -0.447538 Loss_G: 0.287966\n",
      "[831] Loss_D: -0.500255 Loss_G: 0.291419\n",
      "[832] Loss_D: -0.554421 Loss_G: 0.297455\n",
      "[833] Loss_D: -0.560346 Loss_G: 0.298086\n",
      "[834] Loss_D: -0.564220 Loss_G: 0.298566\n",
      "[835] Loss_D: -0.566078 Loss_G: 0.298349\n",
      "[836] Loss_D: -0.567647 Loss_G: 0.299118\n",
      "[837] Loss_D: -0.571786 Loss_G: 0.299361\n",
      "[838] Loss_D: -0.527535 Loss_G: 0.292689\n",
      "[839] Loss_D: -0.548824 Loss_G: 0.297056\n",
      "[840] Loss_D: -0.571819 Loss_G: 0.299059\n",
      "[841] Loss_D: -0.570716 Loss_G: 0.299371\n",
      "[842] Loss_D: -0.570495 Loss_G: 0.299244\n",
      "[843] Loss_D: -0.568522 Loss_G: 0.299366\n",
      "[844] Loss_D: -0.572854 Loss_G: 0.299684\n",
      "[845] Loss_D: -0.570746 Loss_G: 0.299408\n",
      "[846] Loss_D: -0.571680 Loss_G: 0.299054\n",
      "[847] Loss_D: -0.565530 Loss_G: 0.299317\n",
      "[848] Loss_D: -0.570173 Loss_G: 0.299036\n",
      "[849] Loss_D: -0.568488 Loss_G: 0.299073\n",
      "[850] Loss_D: -0.444196 Loss_G: 0.281134\n",
      "[851] Loss_D: -0.441286 Loss_G: 0.288362\n",
      "[852] Loss_D: -0.501671 Loss_G: 0.293267\n",
      "[853] Loss_D: -0.543592 Loss_G: 0.296099\n",
      "[854] Loss_D: -0.552938 Loss_G: 0.297388\n",
      "[855] Loss_D: -0.556854 Loss_G: 0.297613\n",
      "[856] Loss_D: -0.560307 Loss_G: 0.298708\n",
      "[857] Loss_D: -0.565786 Loss_G: 0.298550\n",
      "[858] Loss_D: -0.564308 Loss_G: 0.298512\n",
      "[859] Loss_D: -0.567540 Loss_G: 0.298860\n",
      "[860] Loss_D: -0.565394 Loss_G: 0.298021\n",
      "[861] Loss_D: -0.559012 Loss_G: 0.298322\n",
      "[862] Loss_D: -0.564880 Loss_G: 0.298714\n",
      "[863] Loss_D: -0.570636 Loss_G: 0.299718\n",
      "[864] Loss_D: -0.570159 Loss_G: 0.299844\n",
      "[865] Loss_D: -0.573928 Loss_G: 0.299439\n",
      "[866] Loss_D: -0.573001 Loss_G: 0.299434\n",
      "[867] Loss_D: -0.573948 Loss_G: 0.299398\n",
      "[868] Loss_D: -0.566865 Loss_G: 0.299209\n",
      "[869] Loss_D: -0.572275 Loss_G: 0.299602\n",
      "[870] Loss_D: -0.572955 Loss_G: 0.298962\n",
      "[871] Loss_D: -0.543321 Loss_G: 0.289859\n",
      "[872] Loss_D: -0.423160 Loss_G: 0.287157\n",
      "[873] Loss_D: -0.470188 Loss_G: 0.290614\n",
      "[874] Loss_D: -0.528183 Loss_G: 0.296018\n",
      "[875] Loss_D: -0.552764 Loss_G: 0.297167\n",
      "[876] Loss_D: -0.554353 Loss_G: 0.298601\n",
      "[877] Loss_D: -0.562656 Loss_G: 0.298005\n",
      "[878] Loss_D: -0.561391 Loss_G: 0.298611\n",
      "[879] Loss_D: -0.564921 Loss_G: 0.298929\n",
      "[880] Loss_D: -0.567563 Loss_G: 0.299089\n",
      "[881] Loss_D: -0.564355 Loss_G: 0.298933\n",
      "[882] Loss_D: -0.566655 Loss_G: 0.299001\n",
      "[883] Loss_D: -0.562778 Loss_G: 0.298121\n",
      "[884] Loss_D: -0.567215 Loss_G: 0.298717\n",
      "[885] Loss_D: -0.561245 Loss_G: 0.297792\n",
      "[886] Loss_D: -0.560318 Loss_G: 0.298591\n",
      "[887] Loss_D: -0.568514 Loss_G: 0.299240\n",
      "[888] Loss_D: -0.570925 Loss_G: 0.299196\n",
      "[889] Loss_D: -0.569812 Loss_G: 0.299352\n",
      "[890] Loss_D: -0.567746 Loss_G: 0.298488\n",
      "[891] Loss_D: -0.552439 Loss_G: 0.297142\n",
      "[892] Loss_D: -0.567946 Loss_G: 0.299117\n",
      "[893] Loss_D: -0.557605 Loss_G: 0.294530\n",
      "[894] Loss_D: -0.439324 Loss_G: 0.289040\n",
      "[895] Loss_D: -0.484093 Loss_G: 0.292398\n",
      "[896] Loss_D: -0.538459 Loss_G: 0.296371\n",
      "[897] Loss_D: -0.556493 Loss_G: 0.298381\n",
      "[898] Loss_D: -0.561300 Loss_G: 0.298900\n",
      "[899] Loss_D: -0.565258 Loss_G: 0.298845\n",
      "[900] Loss_D: -0.562412 Loss_G: 0.298908\n",
      "[901] Loss_D: -0.567548 Loss_G: 0.299217\n",
      "[902] Loss_D: -0.568364 Loss_G: 0.299411\n",
      "[903] Loss_D: -0.565882 Loss_G: 0.299075\n",
      "[904] Loss_D: -0.566361 Loss_G: 0.298756\n",
      "[905] Loss_D: -0.568939 Loss_G: 0.298635\n",
      "[906] Loss_D: -0.567057 Loss_G: 0.298640\n",
      "[907] Loss_D: -0.564725 Loss_G: 0.298389\n",
      "[908] Loss_D: -0.565352 Loss_G: 0.298692\n",
      "[909] Loss_D: -0.569064 Loss_G: 0.299178\n",
      "[910] Loss_D: -0.572193 Loss_G: 0.299278\n",
      "[911] Loss_D: -0.573449 Loss_G: 0.299404\n",
      "[912] Loss_D: -0.447964 Loss_G: 0.276197\n",
      "[913] Loss_D: -0.455663 Loss_G: 0.290749\n",
      "[914] Loss_D: -0.510963 Loss_G: 0.293774\n",
      "[915] Loss_D: -0.549776 Loss_G: 0.297012\n",
      "[916] Loss_D: -0.555783 Loss_G: 0.298180\n",
      "[917] Loss_D: -0.562909 Loss_G: 0.298388\n",
      "[918] Loss_D: -0.564581 Loss_G: 0.298889\n",
      "[919] Loss_D: -0.566058 Loss_G: 0.299218\n",
      "[920] Loss_D: -0.567899 Loss_G: 0.299163\n",
      "[921] Loss_D: -0.565641 Loss_G: 0.299026\n",
      "[922] Loss_D: -0.569223 Loss_G: 0.299526\n",
      "[923] Loss_D: -0.566326 Loss_G: 0.298742\n",
      "[924] Loss_D: -0.567955 Loss_G: 0.299152\n",
      "[925] Loss_D: -0.568600 Loss_G: 0.298597\n",
      "[926] Loss_D: -0.567076 Loss_G: 0.298773\n",
      "[927] Loss_D: -0.568806 Loss_G: 0.299202\n",
      "[928] Loss_D: -0.568359 Loss_G: 0.297875\n",
      "[929] Loss_D: -0.560881 Loss_G: 0.298487\n",
      "[930] Loss_D: -0.567939 Loss_G: 0.298775\n",
      "[931] Loss_D: -0.559391 Loss_G: 0.298082\n",
      "[932] Loss_D: -0.561310 Loss_G: 0.296948\n",
      "[933] Loss_D: -0.559479 Loss_G: 0.297614\n",
      "[934] Loss_D: -0.462105 Loss_G: 0.287087\n",
      "[935] Loss_D: -0.482478 Loss_G: 0.291486\n",
      "[936] Loss_D: -0.544410 Loss_G: 0.296153\n",
      "[937] Loss_D: -0.555435 Loss_G: 0.297306\n",
      "[938] Loss_D: -0.560428 Loss_G: 0.298145\n",
      "[939] Loss_D: -0.564921 Loss_G: 0.298523\n",
      "[940] Loss_D: -0.568001 Loss_G: 0.299167\n",
      "[941] Loss_D: -0.566480 Loss_G: 0.299172\n",
      "[942] Loss_D: -0.568187 Loss_G: 0.298525\n",
      "[943] Loss_D: -0.566000 Loss_G: 0.298956\n",
      "[944] Loss_D: -0.568399 Loss_G: 0.299217\n",
      "[945] Loss_D: -0.566732 Loss_G: 0.299030\n",
      "[946] Loss_D: -0.568558 Loss_G: 0.299208\n",
      "[947] Loss_D: -0.567048 Loss_G: 0.298479\n",
      "[948] Loss_D: -0.568443 Loss_G: 0.298844\n",
      "[949] Loss_D: -0.565059 Loss_G: 0.298534\n",
      "[950] Loss_D: -0.441326 Loss_G: 0.277712\n",
      "[951] Loss_D: -0.466447 Loss_G: 0.290595\n",
      "[952] Loss_D: -0.518190 Loss_G: 0.294194\n",
      "[953] Loss_D: -0.545272 Loss_G: 0.296546\n",
      "[954] Loss_D: -0.556266 Loss_G: 0.297687\n",
      "[955] Loss_D: -0.563042 Loss_G: 0.297684\n",
      "[956] Loss_D: -0.563537 Loss_G: 0.298579\n",
      "[957] Loss_D: -0.565316 Loss_G: 0.298763\n",
      "[958] Loss_D: -0.568215 Loss_G: 0.298806\n",
      "[959] Loss_D: -0.571664 Loss_G: 0.299598\n",
      "[960] Loss_D: -0.573236 Loss_G: 0.299720\n",
      "[961] Loss_D: -0.567188 Loss_G: 0.298065\n",
      "[962] Loss_D: -0.486603 Loss_G: 0.289975\n",
      "[963] Loss_D: -0.505571 Loss_G: 0.292564\n",
      "[964] Loss_D: -0.559595 Loss_G: 0.297587\n",
      "[965] Loss_D: -0.569933 Loss_G: 0.299006\n",
      "[966] Loss_D: -0.572113 Loss_G: 0.299026\n",
      "[967] Loss_D: -0.573734 Loss_G: 0.299411\n",
      "[968] Loss_D: -0.572226 Loss_G: 0.299843\n",
      "[969] Loss_D: -0.571585 Loss_G: 0.299272\n",
      "[970] Loss_D: -0.573640 Loss_G: 0.299568\n",
      "[971] Loss_D: -0.457443 Loss_G: 0.282171\n",
      "[972] Loss_D: -0.466503 Loss_G: 0.289150\n",
      "[973] Loss_D: -0.534746 Loss_G: 0.296176\n",
      "[974] Loss_D: -0.563682 Loss_G: 0.298027\n",
      "[975] Loss_D: -0.569717 Loss_G: 0.298939\n",
      "[976] Loss_D: -0.553783 Loss_G: 0.295598\n",
      "[977] Loss_D: -0.549923 Loss_G: 0.297252\n",
      "[978] Loss_D: -0.560814 Loss_G: 0.298288\n",
      "[979] Loss_D: -0.570812 Loss_G: 0.299493\n",
      "[980] Loss_D: -0.576245 Loss_G: 0.300022\n",
      "[981] Loss_D: -0.569016 Loss_G: 0.299109\n",
      "[982] Loss_D: -0.570803 Loss_G: 0.299104\n",
      "[983] Loss_D: -0.509549 Loss_G: 0.288019\n",
      "[984] Loss_D: -0.485943 Loss_G: 0.288717\n",
      "[985] Loss_D: -0.486539 Loss_G: 0.292174\n",
      "[986] Loss_D: -0.475762 Loss_G: 0.288232\n",
      "[987] Loss_D: -0.542937 Loss_G: 0.296966\n",
      "[988] Loss_D: -0.540874 Loss_G: 0.296224\n",
      "[989] Loss_D: -0.568433 Loss_G: 0.299404\n",
      "[990] Loss_D: -0.572477 Loss_G: 0.300031\n",
      "[991] Loss_D: -0.570737 Loss_G: 0.299360\n",
      "[992] Loss_D: -0.568368 Loss_G: 0.299450\n",
      "[993] Loss_D: -0.575598 Loss_G: 0.300211\n",
      "[994] Loss_D: -0.575311 Loss_G: 0.299869\n",
      "[995] Loss_D: -0.483864 Loss_G: 0.290442\n",
      "[996] Loss_D: -0.529668 Loss_G: 0.294374\n",
      "[997] Loss_D: -0.551738 Loss_G: 0.296634\n",
      "[998] Loss_D: -0.448523 Loss_G: 0.286452\n",
      "[999] Loss_D: -0.519160 Loss_G: 0.294138\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    discriminator_losses = []\n",
    "    generator_losses = []\n",
    "    for j in range(0, iterator.num_train, 32):        \n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ############################\n",
    "        \n",
    "        for disc_updates in range(5):\n",
    "            real_examples_full, real_examples, fake_images = iterator.get_train_minibatch(j, 32)\n",
    "            D1 = discriminator(real_examples)\n",
    "            fake = generator(fake_images)\n",
    "            D2 = discriminator(fake)\n",
    "            discriminator_loss = -.5 * ((D1 - D2).mean())\n",
    "            optimizer_discriminator.zero_grad()\n",
    "            discriminator_loss.backward()\n",
    "            optimizer_discriminator.step()\n",
    "\n",
    "            discriminator_losses.append(discriminator_loss.data[0])\n",
    "\n",
    "            # clamp parameters to a cube\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ############################\n",
    "        \n",
    "        generated_images = generator(fake_images)\n",
    "        generator_loss = -.5 * discriminator(\n",
    "            generated_images\n",
    "        ).mean() + loss_criterion(generated_images, real_examples)\n",
    "        optimizer_generator.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "        generator_losses.append(generator_loss.data[0])\n",
    "\n",
    "    print('[%d] Loss_D: %f Loss_G: %f' % (i, np.mean(discriminator_losses), np.mean(generator_losses)))\n",
    "    save_plots(i, fake_images, real_examples, real_examples_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots(i, fake_images, real_examples, real_examples_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-79d320458ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "torch.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 25 is out of bounds for dimension 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a2dabe87bba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 25 is out of bounds for dimension 0 with size 6"
     ]
    }
   ],
   "source": [
    "plt.imshow(real_examples[25].data.cpu().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f535d657510>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYpPfMGoUm/yGUaP8f40bt2y5SZslAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f535d7b86d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fake_images[25].data.cpu().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 3, 64, 64)\n",
    "y = np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

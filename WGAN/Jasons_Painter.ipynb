{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import io\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  3384\n"
     ]
    }
   ],
   "source": [
    "# Seed choice for deterministic results\n",
    "manualSeed = random.randint(1, 10000)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "print(\"Random Seed: \", manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available Painter Supercategories\n",
    "# sports, accessory, animal, outdoor, vehicle, person, indoor, appliance, electronic, furniture\n",
    "# food, kitchen, water, ground, solid, sky, plant, structural, building, textile, window, floor\n",
    "# ceiling, wall, rawmaterial\n",
    "painter_type = \"animal\"\n",
    "image_size = 128\n",
    "lo_bound = image_size // 4\n",
    "up_bound = lo_bound + (image_size // 2)\n",
    "sample_size = 5000\n",
    "train_path = 'inpainting/train2014'\n",
    "dev_path = 'inpainting/val2014'\n",
    "train_annotation_path='inpainting/annotations/instances_train2014.json'\n",
    "dev_annotation_path='inpainting/annotations/instances_val2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_annotation_path, 'r') as R:\n",
    "    train_ann = json.loads(R.read())\n",
    "    \n",
    "with open(dev_annotation_path, 'r') as V:\n",
    "    valid_ann = json.loads(V.read())\n",
    "\n",
    "cat_labels = ['']*91\n",
    "for i in range(len(train_ann['categories'])):\n",
    "    cat_labels[train_ann['categories'][i]['id']] = train_ann['categories'][i]['supercategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterator(object):\n",
    "    \"\"\"Data Iterator for COCO.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path=train_path,\n",
    "        dev_path=dev_path,\n",
    "        train_annotation_path=train_annotation_path,\n",
    "        dev_annotation_path=dev_annotation_path,\n",
    "    ):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        self.train_path = train_path\n",
    "        self.train_annotation_path = train_annotation_path\n",
    "        self.dev_path = dev_path\n",
    "        self.dev_annotation_path = dev_annotation_path\n",
    "        print('Processing data ...')\n",
    "        self._get_real_and_fake_images()\n",
    "\n",
    "    # JMAK - cropping to 128\n",
    "    def _get_real_and_fake_images(self):            \n",
    "        \"\"\"Get real and fake images from path.\"\"\"\n",
    "        self.train_dataset = dset.CocoDetection(\n",
    "            root=self.train_path,\n",
    "            annFile=self.train_annotation_path,\n",
    "            transform=transforms.Compose([\n",
    "                 transforms.CenterCrop(image_size),\n",
    "                 transforms.ToTensor()])\n",
    "        )\n",
    "       \n",
    "        self.valid_dataset = dset.CocoDetection(\n",
    "            root=self.dev_path, \n",
    "            annFile=self.dev_annotation_path,\n",
    "            transform=transforms.Compose([\n",
    "                 transforms.CenterCrop(image_size),\n",
    "                 transforms.ToTensor()])\n",
    "        )\n",
    "                \n",
    "        # ELDRICK: First, copy over desired number of training and validation. \n",
    "        print('Populating training images & captions ...')\n",
    "        train_images = []\n",
    "        # There appears to be one image missing for some weird reason.\n",
    "        try:\n",
    "            for img, label in self.train_dataset:\n",
    "                area_index = 0\n",
    "                largest_area = 0\n",
    "                try:\n",
    "                    for j in range(len(label)):\n",
    "                        if label[j]['area'] > largest_area:\n",
    "                            largest_area = label[j]['area']\n",
    "                            area_index = j\n",
    "                    img_cat_id = label[area_index]['category_id']\n",
    "                except:\n",
    "                    pass\n",
    "                if cat_labels[img_cat_id] == painter_type:\n",
    "                    train_images.append(img)\n",
    "                if len(train_images) % 500 == 0:\n",
    "                    print(\"Gathered \", len(train_images), \" training images so far\")\n",
    "                if len(train_images) == sample_size:\n",
    "                    break\n",
    "        except IOError:\n",
    "            pass\n",
    "        \n",
    "        train_images = torch.stack(train_images)\n",
    "        \n",
    "        # ELDRICK: Second, changed this to match above to terminate\n",
    "        print('Populating validation images ...')\n",
    "        valid_images = []\n",
    "        try:\n",
    "            for img, label in self.valid_dataset:\n",
    "                area_index = 0\n",
    "                largest_area = 0\n",
    "                try:\n",
    "                    for j in range(len(label)):\n",
    "                        if label[j]['area'] > largest_area:\n",
    "                            largest_area = label[j]['area']\n",
    "                            area_index = j\n",
    "                    img_cat_id = label[area_index]['category_id']\n",
    "                except:\n",
    "                    pass\n",
    "                if cat_labels[img_cat_id] == painter_type:\n",
    "                    valid_images.append(img)\n",
    "                if len(valid_images) % 500 == 0:\n",
    "                    print(\"Gathered \", len(valid_images), \" validation images so far\")\n",
    "                if len(valid_images) == sample_size:\n",
    "                    break\n",
    "        except IOError:\n",
    "            pass\n",
    "        \n",
    "        valid_images = torch.stack(valid_images)\n",
    "\n",
    "        # ELDRICK: Crop out 128 by 128\n",
    "        # JMAK: Crop out 64x64 \n",
    "        print('Cropping 64x64 patch for training images ...')\n",
    "        noisy_train_images = copy.deepcopy(train_images.numpy())\n",
    "        noisy_train_images[:, :, lo_bound:up_bound, lo_bound:up_bound] = 0\n",
    "        noisy_train_images = torch.from_numpy(noisy_train_images)\n",
    "\n",
    "        print('Cropping 64x64 patch for validation images ...')\n",
    "        noisy_valid_images = copy.deepcopy(valid_images.numpy())\n",
    "        noisy_valid_images[:, :, lo_bound:up_bound, lo_bound:up_bound] = 0\n",
    "        noisy_valid_images = torch.from_numpy(noisy_valid_images)\n",
    "        \n",
    "        self.train_images = train_images\n",
    "        self.valid_images = valid_images\n",
    "\n",
    "        self.noisy_train_images = noisy_train_images\n",
    "        self.noisy_valid_images = noisy_valid_images\n",
    "                \n",
    "        self.num_train = len(train_images)\n",
    "        self.num_valid = len(valid_images)\n",
    "\n",
    "    # Return proper sized samples from minibatch - 128x128\n",
    "    # return a 64 x 64 minibatch - JMAK\n",
    "    def get_train_minibatch(self, index, batch_size):\n",
    "        \"\"\"Return a minibatch of real and fake examples.\"\"\"\n",
    "        real_examples = Variable(self.train_images[index: index + batch_size]).cuda()\n",
    "        fake_examples = Variable(self.noisy_train_images[index: index + batch_size]).cuda()\n",
    "        return real_examples, real_examples[:, :, lo_bound:up_bound, lo_bound:up_bound], fake_examples\n",
    "\n",
    "    def get_valid_minibatch(self, index, batch_size):\n",
    "        \"\"\"Return a minibatch of real and fake examples.\"\"\"\n",
    "        real_examples = Variable(self.valid_images[index: index + batch_size]).cuda()\n",
    "        fake_examples = Variable(self.noisy_valid_images[index: index + batch_size]).cuda()\n",
    "        return real_examples, real_examples[:, :, lo_bound:up_bound, lo_bound:up_bound], fake_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data ...\n",
      "loading annotations into memory...\n",
      "Done (t=9.91s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Populating training images & captions ...\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  0  training images so far\n",
      "Gathered  500  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1000  training images so far\n",
      "Gathered  1500  training images so far\n",
      "Gathered  2000  training images so far\n",
      "Gathered  2500  training images so far\n",
      "Gathered  3000  training images so far\n",
      "Gathered  3000  training images so far\n",
      "Gathered  3000  training images so far\n",
      "Gathered  3000  training images so far\n",
      "Gathered  3500  training images so far\n",
      "Gathered  3500  training images so far\n",
      "Gathered  3500  training images so far\n",
      "Gathered  3500  training images so far\n",
      "Gathered  4000  training images so far\n",
      "Gathered  4000  training images so far\n",
      "Gathered  4000  training images so far\n",
      "Gathered  4500  training images so far\n",
      "Gathered  4500  training images so far\n",
      "Gathered  5000  training images so far\n",
      "Populating validation images ...\n",
      "Gathered  0  validation images so far\n",
      "Gathered  0  validation images so far\n",
      "Gathered  500  validation images so far\n",
      "Gathered  1000  validation images so far\n",
      "Gathered  1000  validation images so far\n",
      "Gathered  1500  validation images so far\n",
      "Gathered  2000  validation images so far\n",
      "Gathered  2000  validation images so far\n",
      "Gathered  2000  validation images so far\n",
      "Gathered  2500  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3000  validation images so far\n",
      "Gathered  3500  validation images so far\n",
      "Gathered  4000  validation images so far\n",
      "Gathered  4000  validation images so far\n",
      "Gathered  4000  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  4500  validation images so far\n",
      "Gathered  5000  validation images so far\n",
      "Cropping 64x64 patch for training images ...\n",
      "Cropping 64x64 patch for validation images ...\n",
      "Number of Total Class Samples, Train:  5000\n",
      "Number of Total Class Samples, Valid:  5000\n"
     ]
    }
   ],
   "source": [
    "iterator = DataIterator()\n",
    "print(\"Number of Total Class Samples, Train: \", iterator.num_train)\n",
    "print(\"Number of Total Class Samples, Valid: \", iterator.num_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9620654126b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# _axes_class is set in the subplot_class_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# add a layout box to this, for both the full axis, and the poss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# of the axis.  We need both because the axes may become smaller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# this call may differ for non-sep axes, e.g., polar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfacecolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mfacecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.facecolor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_init_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;34m\"move this out of __init__ because non-separable axes don't use it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXAxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bottom'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, pickradius)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# self.set_label_text would change isDefault_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;31m# Clear the callback registry for this axis, or it may \"leak\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_scale\u001b[0;34m(self, value, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_locators_and_formatters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misDefault_majloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/scale.py\u001b[0m in \u001b[0;36mset_default_locators_and_formatters\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlinear\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScalarFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_minor_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNullFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2493\u001b[0m             \u001b[0mnbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0mMaxNLocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                     \"Keywords are required for all arguments except 'nbins'\")\n\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_staircase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'integer'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(steps)\u001b[0m\n\u001b[1;32m   1847\u001b[0m                              'from 1 to 10')\n\u001b[1;32m   1848\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps argument must be uniformly increasing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/envs/cs231n/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdiff\u001b[0;34m(a, n, axis)\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0mslice2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1944\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_equal\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1945\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool_'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "j = np.random.randint(low=0, high=iterator.num_train)\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(iterator.train_images[j].numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(iterator.noisy_train_images[j].numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator module.\"\"\"\n",
    "\n",
    "    def __init__(self, start_filter):\n",
    "        \"\"\"Initialize generator.\"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "        # input is (nc) x 128 x 128\n",
    "        nn.Conv2d(3,start_filter,4,2,1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # state size: (nef) x 64 x 64\n",
    "        nn.Conv2d(start_filter,start_filter,4,2,1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # state size: (nef) x 32 x 32\n",
    "        nn.Conv2d(start_filter,start_filter*2,4,2,1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter*2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # state size: (nef*2) x 16 x 16\n",
    "        nn.Conv2d(start_filter*2,start_filter*4,4,2,1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter*4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # state size: (nef*4) x 8 x 8\n",
    "        nn.Conv2d(start_filter*4,start_filter*8,4,2,1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter*8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # state size: (nef*8) x 4 x 4\n",
    "        nn.Conv2d(start_filter*8,4000,4, bias=False),\n",
    "        \n",
    "        # state size: (nBottleneck) x 1 x 1\n",
    "        nn.BatchNorm2d(4000),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        # input is Bottleneck, going into a convolution\n",
    "        nn.ConvTranspose2d(4000, start_filter * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(start_filter * 8),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        nn.ConvTranspose2d(start_filter * 8, start_filter * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter * 4),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        nn.ConvTranspose2d(start_filter * 4, start_filter * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter * 2),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        nn.ConvTranspose2d(start_filter * 2, start_filter, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(start_filter),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        # state size. (ngf) x 32 x 32\n",
    "        nn.ConvTranspose2d(start_filter, 3, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator.\"\"\"\n",
    "\n",
    "    def __init__(self, start_filter):\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(3, start_filter, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(start_filter, start_filter * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(start_filter * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(start_filter * 2, start_filter * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(start_filter * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(start_filter * 4, start_filter * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(start_filter * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(start_filter * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate_gen = 1e-3\n",
    "learning_rate_dis = 1e-3\n",
    "betas_gen = (0.5, 0.999)\n",
    "betas_dis = (0.5, 0.999)\n",
    "\n",
    "generator = Generator(start_filter=64).cuda()\n",
    "discriminator = Discriminator(start_filter=64).cuda()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=learning_rate_gen, betas=betas_gen)\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=learning_rate_dis, betas=betas_dis)\n",
    "clamp_lower = -0.03\n",
    "clamp_upper = 0.03\n",
    "loss_criterion = nn.MSELoss().cuda()\n",
    "save_dir = 'inpainting/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(epoch, fake_images, real_images, real_examples_full):\n",
    "    # ELDRICK: Change random to fit your sample size\n",
    "    j = np.random.randint(low=0, high=iterator.num_valid)\n",
    "    # ELDRICK: Change minibatch size to fit samples\n",
    "    real_examples_full, real_examples, fake_images = iterator.get_valid_minibatch(j, 64)\n",
    "    generator.eval()\n",
    "    reconstructions = generator(fake_images)\n",
    "    reconstructions = reconstructions.data.cpu().numpy()\n",
    "    real = real_examples_full.data.cpu().numpy()\n",
    "    real_copy = copy.deepcopy(real)\n",
    "    real_copy[:, :, lo_bound:up_bound, lo_bound:up_bound] = reconstructions\n",
    "    real_copy = torch.from_numpy(real_copy)\n",
    "    real = torch.from_numpy(real)\n",
    "    out_tensor = torch.zeros(1, real_copy.size(1), real_copy.size(2), real_copy.size(3))\n",
    "    for zz, zzz in zip(real_copy[:10], real[:10]):\n",
    "        out_tensor = torch.cat([out_tensor, zz.unsqueeze(0)])\n",
    "        out_tensor = torch.cat([out_tensor, zzz.unsqueeze(0)])\n",
    "    vutils.save_image(out_tensor[1:], 'inpainting/samples/epoch_s%d_samples.png' % (epoch), normalize=True, scale_each=True, nrow=4)\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Loss_D: 0.375053 Loss_G: 0.053182\n",
      "[1] Loss_D: 0.777685 Loss_G: 0.035414\n",
      "[2] Loss_D: 0.663081 Loss_G: 0.033636\n",
      "[3] Loss_D: 0.062871 Loss_G: 0.034997\n",
      "[4] Loss_D: 0.005371 Loss_G: 0.034718\n",
      "[5] Loss_D: 0.004128 Loss_G: 0.034118\n",
      "[6] Loss_D: 0.003657 Loss_G: 0.033505\n",
      "[7] Loss_D: 0.869406 Loss_G: 0.029199\n",
      "[8] Loss_D: 0.564921 Loss_G: 0.029121\n",
      "[9] Loss_D: 0.061893 Loss_G: 0.031286\n",
      "[10] Loss_D: 0.003412 Loss_G: 0.030793\n",
      "[11] Loss_D: 0.003260 Loss_G: 0.030026\n",
      "[12] Loss_D: 0.002731 Loss_G: 0.029255\n",
      "[13] Loss_D: 0.002536 Loss_G: 0.028660\n",
      "[14] Loss_D: 0.881148 Loss_G: 0.023950\n",
      "[15] Loss_D: 0.452676 Loss_G: 0.024448\n",
      "[16] Loss_D: 0.746494 Loss_G: 0.022719\n",
      "[17] Loss_D: 0.480381 Loss_G: 0.023171\n",
      "[18] Loss_D: 0.659718 Loss_G: 0.021842\n",
      "[19] Loss_D: 0.667160 Loss_G: 0.021135\n",
      "[20] Loss_D: 0.460765 Loss_G: 0.020845\n",
      "[21] Loss_D: 0.504489 Loss_G: 0.020299\n",
      "[22] Loss_D: 1.033842 Loss_G: 0.017968\n",
      "[23] Loss_D: 0.334711 Loss_G: 0.019366\n",
      "[24] Loss_D: 0.515729 Loss_G: 0.018535\n",
      "[25] Loss_D: 0.543140 Loss_G: 0.017979\n",
      "[26] Loss_D: 0.289634 Loss_G: 0.018511\n",
      "[27] Loss_D: 0.830276 Loss_G: 0.016481\n",
      "[28] Loss_D: 0.869275 Loss_G: 0.015791\n",
      "[29] Loss_D: 0.514317 Loss_G: 0.016563\n",
      "[30] Loss_D: 0.627821 Loss_G: 0.015736\n",
      "[31] Loss_D: 0.463426 Loss_G: 0.015906\n",
      "[32] Loss_D: 0.890296 Loss_G: 0.014147\n",
      "[33] Loss_D: 0.939062 Loss_G: 0.013680\n",
      "[34] Loss_D: 0.487833 Loss_G: 0.015160\n",
      "[35] Loss_D: 0.499839 Loss_G: 0.015339\n",
      "[36] Loss_D: 0.602391 Loss_G: 0.014413\n",
      "[37] Loss_D: 0.736484 Loss_G: 0.013451\n",
      "[38] Loss_D: 0.894258 Loss_G: 0.012492\n",
      "[39] Loss_D: 0.863862 Loss_G: 0.012465\n",
      "[40] Loss_D: 0.911553 Loss_G: 0.012014\n",
      "[41] Loss_D: 0.614562 Loss_G: 0.012918\n",
      "[42] Loss_D: 0.416149 Loss_G: 0.013620\n",
      "[43] Loss_D: 0.477649 Loss_G: 0.013381\n",
      "[44] Loss_D: 0.613405 Loss_G: 0.012679\n",
      "[45] Loss_D: 0.635923 Loss_G: 0.012613\n",
      "[46] Loss_D: 0.540574 Loss_G: 0.012682\n",
      "[47] Loss_D: 0.625102 Loss_G: 0.012416\n",
      "[48] Loss_D: 0.592795 Loss_G: 0.012664\n",
      "[49] Loss_D: 0.539631 Loss_G: 0.012619\n",
      "[50] Loss_D: 0.654304 Loss_G: 0.011863\n",
      "[51] Loss_D: 0.944668 Loss_G: 0.010588\n",
      "[52] Loss_D: 0.691935 Loss_G: 0.011215\n",
      "[53] Loss_D: 0.649293 Loss_G: 0.011451\n",
      "[54] Loss_D: 0.598909 Loss_G: 0.011705\n",
      "[55] Loss_D: 0.651063 Loss_G: 0.011507\n",
      "[56] Loss_D: 0.616274 Loss_G: 0.011514\n",
      "[57] Loss_D: 0.631245 Loss_G: 0.011223\n",
      "[58] Loss_D: 0.526103 Loss_G: 0.011235\n",
      "[59] Loss_D: 0.657594 Loss_G: 0.010742\n",
      "[60] Loss_D: 0.613610 Loss_G: 0.010634\n",
      "[61] Loss_D: 0.662962 Loss_G: 0.010647\n",
      "[62] Loss_D: 0.612504 Loss_G: 0.010857\n",
      "[63] Loss_D: 0.614527 Loss_G: 0.010866\n",
      "[64] Loss_D: 0.582235 Loss_G: 0.010662\n",
      "[65] Loss_D: 0.619391 Loss_G: 0.010294\n",
      "[66] Loss_D: 0.639778 Loss_G: 0.010266\n",
      "[67] Loss_D: 0.660513 Loss_G: 0.010000\n",
      "[68] Loss_D: 0.655653 Loss_G: 0.010156\n",
      "[69] Loss_D: 0.648499 Loss_G: 0.010206\n",
      "[70] Loss_D: 0.665227 Loss_G: 0.010192\n",
      "[71] Loss_D: 0.623557 Loss_G: 0.010069\n",
      "[72] Loss_D: 0.590033 Loss_G: 0.010026\n",
      "[73] Loss_D: 0.619411 Loss_G: 0.009982\n",
      "[74] Loss_D: 0.621808 Loss_G: 0.009741\n",
      "[75] Loss_D: 0.614183 Loss_G: 0.009649\n",
      "[76] Loss_D: 0.610258 Loss_G: 0.009575\n",
      "[77] Loss_D: 0.635878 Loss_G: 0.009482\n",
      "[78] Loss_D: 0.634295 Loss_G: 0.009481\n",
      "[79] Loss_D: 0.604685 Loss_G: 0.009523\n",
      "[80] Loss_D: 0.609591 Loss_G: 0.009481\n",
      "[81] Loss_D: 0.636652 Loss_G: 0.009324\n",
      "[82] Loss_D: 0.649151 Loss_G: 0.009088\n",
      "[83] Loss_D: 0.629570 Loss_G: 0.009023\n",
      "[84] Loss_D: 0.617547 Loss_G: 0.008937\n",
      "[85] Loss_D: 0.617588 Loss_G: 0.008868\n",
      "[86] Loss_D: 0.617208 Loss_G: 0.008795\n",
      "[87] Loss_D: 0.602070 Loss_G: 0.008898\n",
      "[88] Loss_D: 0.640042 Loss_G: 0.008673\n",
      "[89] Loss_D: 0.682944 Loss_G: 0.008460\n",
      "[90] Loss_D: 0.621061 Loss_G: 0.008720\n",
      "[91] Loss_D: 0.588324 Loss_G: 0.008733\n",
      "[92] Loss_D: 0.634433 Loss_G: 0.008658\n",
      "[93] Loss_D: 0.663530 Loss_G: 0.008539\n",
      "[94] Loss_D: 0.631819 Loss_G: 0.008558\n",
      "[95] Loss_D: 0.627990 Loss_G: 0.008601\n",
      "[96] Loss_D: 0.652164 Loss_G: 0.008449\n",
      "[97] Loss_D: 0.635996 Loss_G: 0.008336\n",
      "[98] Loss_D: 0.680765 Loss_G: 0.008067\n",
      "[99] Loss_D: 0.667890 Loss_G: 0.008027\n",
      "[100] Loss_D: 0.637868 Loss_G: 0.008152\n",
      "[101] Loss_D: 0.642345 Loss_G: 0.008167\n",
      "[102] Loss_D: 0.659474 Loss_G: 0.008123\n",
      "[103] Loss_D: 0.644606 Loss_G: 0.008155\n",
      "[104] Loss_D: 0.665145 Loss_G: 0.008040\n",
      "[105] Loss_D: 0.658470 Loss_G: 0.008113\n",
      "[106] Loss_D: 0.610816 Loss_G: 0.007996\n",
      "[107] Loss_D: 0.713577 Loss_G: 0.007832\n",
      "[108] Loss_D: 0.655893 Loss_G: 0.007899\n",
      "[109] Loss_D: 0.662541 Loss_G: 0.007792\n",
      "[110] Loss_D: 0.660434 Loss_G: 0.007777\n",
      "[111] Loss_D: 0.661199 Loss_G: 0.007720\n",
      "[112] Loss_D: 0.676847 Loss_G: 0.007698\n",
      "[113] Loss_D: 0.637310 Loss_G: 0.007773\n",
      "[114] Loss_D: 0.646558 Loss_G: 0.007793\n",
      "[115] Loss_D: 0.687349 Loss_G: 0.007612\n",
      "[116] Loss_D: 0.704212 Loss_G: 0.007567\n",
      "[117] Loss_D: 0.659715 Loss_G: 0.007696\n",
      "[118] Loss_D: 0.652708 Loss_G: 0.007755\n",
      "[119] Loss_D: 0.717415 Loss_G: 0.007599\n",
      "[120] Loss_D: 0.663323 Loss_G: 0.007547\n",
      "[121] Loss_D: 0.676703 Loss_G: 0.007521\n",
      "[122] Loss_D: 0.671791 Loss_G: 0.007534\n",
      "[123] Loss_D: 0.688772 Loss_G: 0.007444\n",
      "[124] Loss_D: 0.658522 Loss_G: 0.007381\n",
      "[125] Loss_D: 0.694290 Loss_G: 0.007297\n",
      "[126] Loss_D: 0.686519 Loss_G: 0.007288\n",
      "[127] Loss_D: 0.644900 Loss_G: 0.007479\n",
      "[128] Loss_D: 0.701054 Loss_G: 0.007343\n",
      "[129] Loss_D: 0.695210 Loss_G: 0.007367\n",
      "[130] Loss_D: 0.669603 Loss_G: 0.007307\n",
      "[131] Loss_D: 0.751014 Loss_G: 0.007062\n",
      "[132] Loss_D: 0.791084 Loss_G: 0.006828\n",
      "[133] Loss_D: 0.749200 Loss_G: 0.007017\n",
      "[134] Loss_D: 0.677243 Loss_G: 0.007132\n",
      "[135] Loss_D: 0.647800 Loss_G: 0.007189\n",
      "[136] Loss_D: 0.668687 Loss_G: 0.007242\n",
      "[137] Loss_D: 0.670164 Loss_G: 0.007220\n",
      "[138] Loss_D: 0.695023 Loss_G: 0.007184\n",
      "[139] Loss_D: 0.640121 Loss_G: 0.007303\n",
      "[140] Loss_D: 0.638145 Loss_G: 0.007321\n",
      "[141] Loss_D: 0.685085 Loss_G: 0.007322\n",
      "[142] Loss_D: 0.689576 Loss_G: 0.007367\n",
      "[143] Loss_D: 0.636157 Loss_G: 0.007479\n",
      "[144] Loss_D: 0.660913 Loss_G: 0.007311\n",
      "[145] Loss_D: 0.667172 Loss_G: 0.007249\n",
      "[146] Loss_D: 0.689477 Loss_G: 0.007178\n",
      "[147] Loss_D: 0.690638 Loss_G: 0.007188\n",
      "[148] Loss_D: 0.644122 Loss_G: 0.007257\n",
      "[149] Loss_D: 0.687565 Loss_G: 0.007104\n",
      "[150] Loss_D: 0.645384 Loss_G: 0.007058\n",
      "[151] Loss_D: 0.761964 Loss_G: 0.006844\n",
      "[152] Loss_D: 0.714635 Loss_G: 0.006955\n",
      "[153] Loss_D: 0.722649 Loss_G: 0.006951\n",
      "[154] Loss_D: 0.742988 Loss_G: 0.006883\n",
      "[155] Loss_D: 0.750096 Loss_G: 0.006803\n",
      "[156] Loss_D: 0.730763 Loss_G: 0.006853\n",
      "[157] Loss_D: 0.732128 Loss_G: 0.006728\n",
      "[158] Loss_D: 0.746080 Loss_G: 0.006596\n",
      "[159] Loss_D: 0.785046 Loss_G: 0.006546\n",
      "[160] Loss_D: 0.808008 Loss_G: 0.006448\n",
      "[161] Loss_D: 0.770263 Loss_G: 0.006468\n",
      "[162] Loss_D: 0.745047 Loss_G: 0.006541\n",
      "[163] Loss_D: 0.715594 Loss_G: 0.006648\n",
      "[164] Loss_D: 0.754178 Loss_G: 0.006536\n",
      "[165] Loss_D: 0.751412 Loss_G: 0.006599\n",
      "[166] Loss_D: 0.753789 Loss_G: 0.006530\n",
      "[167] Loss_D: 0.718962 Loss_G: 0.006625\n",
      "[168] Loss_D: 0.774740 Loss_G: 0.006406\n",
      "[169] Loss_D: 0.739655 Loss_G: 0.006427\n",
      "[170] Loss_D: 0.774079 Loss_G: 0.006335\n",
      "[171] Loss_D: 0.822180 Loss_G: 0.006236\n",
      "[172] Loss_D: 0.758679 Loss_G: 0.006284\n",
      "[173] Loss_D: 0.745193 Loss_G: 0.006429\n",
      "[174] Loss_D: 0.872886 Loss_G: 0.006165\n",
      "[175] Loss_D: 0.846194 Loss_G: 0.006157\n",
      "[176] Loss_D: 0.756194 Loss_G: 0.006292\n",
      "[177] Loss_D: 0.769623 Loss_G: 0.006235\n",
      "[178] Loss_D: 0.781970 Loss_G: 0.006281\n",
      "[179] Loss_D: 0.830926 Loss_G: 0.006043\n",
      "[180] Loss_D: 0.774240 Loss_G: 0.006238\n",
      "[181] Loss_D: 0.729234 Loss_G: 0.006236\n",
      "[182] Loss_D: 0.761214 Loss_G: 0.006231\n",
      "[183] Loss_D: 0.784957 Loss_G: 0.006112\n",
      "[184] Loss_D: 0.829887 Loss_G: 0.006037\n",
      "[185] Loss_D: 0.764622 Loss_G: 0.006102\n",
      "[186] Loss_D: 0.777333 Loss_G: 0.006066\n",
      "[187] Loss_D: 0.770143 Loss_G: 0.006106\n",
      "[188] Loss_D: 0.733278 Loss_G: 0.006222\n",
      "[189] Loss_D: 0.759831 Loss_G: 0.006114\n",
      "[190] Loss_D: 0.709970 Loss_G: 0.006203\n",
      "[191] Loss_D: 0.734917 Loss_G: 0.006179\n",
      "[192] Loss_D: 0.715219 Loss_G: 0.006205\n",
      "[193] Loss_D: 0.703821 Loss_G: 0.006244\n",
      "[194] Loss_D: 0.758964 Loss_G: 0.006134\n",
      "[195] Loss_D: 0.802681 Loss_G: 0.006058\n",
      "[196] Loss_D: 0.763135 Loss_G: 0.006098\n",
      "[197] Loss_D: 0.724877 Loss_G: 0.006124\n",
      "[198] Loss_D: 0.741782 Loss_G: 0.006003\n",
      "[199] Loss_D: 0.753717 Loss_G: 0.005956\n",
      "[200] Loss_D: 0.809729 Loss_G: 0.005845\n",
      "[201] Loss_D: 0.769333 Loss_G: 0.005918\n",
      "[202] Loss_D: 0.719978 Loss_G: 0.005962\n",
      "[203] Loss_D: 0.712806 Loss_G: 0.005916\n",
      "[204] Loss_D: 0.722359 Loss_G: 0.006003\n",
      "[205] Loss_D: 0.769015 Loss_G: 0.005785\n",
      "[206] Loss_D: 0.779846 Loss_G: 0.005784\n",
      "[207] Loss_D: 0.780480 Loss_G: 0.005806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208] Loss_D: 0.754919 Loss_G: 0.005901\n",
      "[209] Loss_D: 0.772170 Loss_G: 0.005834\n",
      "[210] Loss_D: 0.742017 Loss_G: 0.005863\n",
      "[211] Loss_D: 0.845156 Loss_G: 0.005677\n",
      "[212] Loss_D: 0.744390 Loss_G: 0.005862\n",
      "[213] Loss_D: 0.808225 Loss_G: 0.005703\n",
      "[214] Loss_D: 0.796912 Loss_G: 0.005675\n",
      "[215] Loss_D: 0.715586 Loss_G: 0.005910\n",
      "[216] Loss_D: 0.773026 Loss_G: 0.005751\n",
      "[217] Loss_D: 0.746871 Loss_G: 0.005793\n",
      "[218] Loss_D: 0.803493 Loss_G: 0.005704\n",
      "[219] Loss_D: 0.784419 Loss_G: 0.005661\n",
      "[220] Loss_D: 0.741913 Loss_G: 0.005835\n",
      "[221] Loss_D: 0.723441 Loss_G: 0.005829\n",
      "[222] Loss_D: 0.745060 Loss_G: 0.005783\n",
      "[223] Loss_D: 0.771099 Loss_G: 0.005791\n",
      "[224] Loss_D: 0.752143 Loss_G: 0.005816\n",
      "[225] Loss_D: 0.787639 Loss_G: 0.005711\n",
      "[226] Loss_D: 0.860509 Loss_G: 0.005559\n",
      "[227] Loss_D: 0.800591 Loss_G: 0.005617\n",
      "[228] Loss_D: 0.768600 Loss_G: 0.005663\n",
      "[229] Loss_D: 0.773716 Loss_G: 0.005710\n",
      "[230] Loss_D: 0.776678 Loss_G: 0.005674\n",
      "[231] Loss_D: 0.837821 Loss_G: 0.005492\n",
      "[232] Loss_D: 0.827596 Loss_G: 0.005488\n",
      "[233] Loss_D: 0.768680 Loss_G: 0.005700\n",
      "[234] Loss_D: 0.742887 Loss_G: 0.005686\n",
      "[235] Loss_D: 0.775262 Loss_G: 0.005703\n",
      "[236] Loss_D: 0.750211 Loss_G: 0.005758\n",
      "[237] Loss_D: 0.694994 Loss_G: 0.005961\n",
      "[238] Loss_D: 0.712333 Loss_G: 0.005872\n",
      "[239] Loss_D: 0.710359 Loss_G: 0.005906\n",
      "[240] Loss_D: 0.895007 Loss_G: 0.005533\n",
      "[241] Loss_D: 0.779437 Loss_G: 0.005713\n",
      "[242] Loss_D: 0.738507 Loss_G: 0.005854\n",
      "[243] Loss_D: 0.766953 Loss_G: 0.005833\n",
      "[244] Loss_D: 0.815266 Loss_G: 0.005690\n",
      "[245] Loss_D: 0.831138 Loss_G: 0.005672\n",
      "[246] Loss_D: 0.805606 Loss_G: 0.005761\n",
      "[247] Loss_D: 0.817903 Loss_G: 0.005643\n",
      "[248] Loss_D: 0.879197 Loss_G: 0.005515\n",
      "[249] Loss_D: 0.828973 Loss_G: 0.005654\n",
      "[250] Loss_D: 0.817122 Loss_G: 0.005763\n",
      "[251] Loss_D: 0.863121 Loss_G: 0.005597\n",
      "[252] Loss_D: 0.854220 Loss_G: 0.005624\n",
      "[253] Loss_D: 0.840258 Loss_G: 0.005583\n",
      "[254] Loss_D: 0.834578 Loss_G: 0.005587\n",
      "[255] Loss_D: 0.798485 Loss_G: 0.005659\n",
      "[256] Loss_D: 0.813464 Loss_G: 0.005651\n",
      "[257] Loss_D: 0.794296 Loss_G: 0.005667\n",
      "[258] Loss_D: 0.853120 Loss_G: 0.005505\n",
      "[259] Loss_D: 0.948159 Loss_G: 0.005306\n",
      "[260] Loss_D: 0.870341 Loss_G: 0.005389\n",
      "[261] Loss_D: 0.886353 Loss_G: 0.005303\n",
      "[262] Loss_D: 0.838839 Loss_G: 0.005355\n",
      "[263] Loss_D: 0.862074 Loss_G: 0.005394\n",
      "[264] Loss_D: 0.850886 Loss_G: 0.005382\n",
      "[265] Loss_D: 1.016381 Loss_G: 0.005035\n",
      "[266] Loss_D: 0.879528 Loss_G: 0.005275\n",
      "[267] Loss_D: 0.874133 Loss_G: 0.005363\n",
      "[268] Loss_D: 0.852199 Loss_G: 0.005396\n",
      "[269] Loss_D: 0.878671 Loss_G: 0.005327\n",
      "[270] Loss_D: 0.863657 Loss_G: 0.005323\n",
      "[271] Loss_D: 0.875616 Loss_G: 0.005226\n",
      "[272] Loss_D: 0.879031 Loss_G: 0.005321\n",
      "[273] Loss_D: 0.973970 Loss_G: 0.004998\n",
      "[274] Loss_D: 0.881357 Loss_G: 0.005154\n",
      "[275] Loss_D: 0.908933 Loss_G: 0.005185\n",
      "[276] Loss_D: 0.902179 Loss_G: 0.005203\n",
      "[277] Loss_D: 0.945420 Loss_G: 0.005005\n",
      "[278] Loss_D: 0.888625 Loss_G: 0.005073\n",
      "[279] Loss_D: 0.884985 Loss_G: 0.005103\n",
      "[280] Loss_D: 0.873717 Loss_G: 0.005092\n",
      "[281] Loss_D: 0.852824 Loss_G: 0.005269\n",
      "[282] Loss_D: 0.820909 Loss_G: 0.005359\n",
      "[283] Loss_D: 0.792356 Loss_G: 0.005357\n",
      "[284] Loss_D: 0.788970 Loss_G: 0.005335\n",
      "[285] Loss_D: 0.823825 Loss_G: 0.005349\n",
      "[286] Loss_D: 0.770337 Loss_G: 0.005439\n",
      "[287] Loss_D: 0.756341 Loss_G: 0.005476\n",
      "[288] Loss_D: 0.737342 Loss_G: 0.005519\n",
      "[289] Loss_D: 0.891676 Loss_G: 0.005188\n",
      "[290] Loss_D: 0.775988 Loss_G: 0.005344\n",
      "[291] Loss_D: 0.746155 Loss_G: 0.005418\n",
      "[292] Loss_D: 0.764795 Loss_G: 0.005418\n",
      "[293] Loss_D: 0.864920 Loss_G: 0.005215\n",
      "[294] Loss_D: 0.761398 Loss_G: 0.005268\n",
      "[295] Loss_D: 0.751852 Loss_G: 0.005326\n",
      "[296] Loss_D: 0.814234 Loss_G: 0.005214\n",
      "[297] Loss_D: 0.750751 Loss_G: 0.005354\n",
      "[298] Loss_D: 0.793562 Loss_G: 0.005281\n",
      "[299] Loss_D: 0.796119 Loss_G: 0.005235\n",
      "[300] Loss_D: 0.823998 Loss_G: 0.005220\n",
      "[301] Loss_D: 0.880821 Loss_G: 0.005095\n",
      "[302] Loss_D: 0.850302 Loss_G: 0.005086\n",
      "[303] Loss_D: 0.850843 Loss_G: 0.005106\n",
      "[304] Loss_D: 0.843724 Loss_G: 0.005108\n",
      "[305] Loss_D: 0.908152 Loss_G: 0.004994\n",
      "[306] Loss_D: 0.820880 Loss_G: 0.005135\n",
      "[307] Loss_D: 0.788070 Loss_G: 0.005183\n",
      "[308] Loss_D: 0.807030 Loss_G: 0.005085\n",
      "[309] Loss_D: 0.838439 Loss_G: 0.005112\n",
      "[310] Loss_D: 0.832681 Loss_G: 0.005103\n",
      "[311] Loss_D: 0.837944 Loss_G: 0.005070\n",
      "[312] Loss_D: 0.812990 Loss_G: 0.005154\n",
      "[313] Loss_D: 0.841498 Loss_G: 0.005118\n",
      "[314] Loss_D: 0.807036 Loss_G: 0.005092\n",
      "[315] Loss_D: 0.952308 Loss_G: 0.004879\n",
      "[316] Loss_D: 0.903377 Loss_G: 0.004876\n",
      "[317] Loss_D: 0.827691 Loss_G: 0.004919\n",
      "[318] Loss_D: 0.965555 Loss_G: 0.004741\n",
      "[319] Loss_D: 0.881952 Loss_G: 0.004841\n",
      "[320] Loss_D: 0.814597 Loss_G: 0.005036\n",
      "[321] Loss_D: 0.830022 Loss_G: 0.005017\n",
      "[322] Loss_D: 0.791445 Loss_G: 0.005029\n",
      "[323] Loss_D: 0.801762 Loss_G: 0.004999\n",
      "[324] Loss_D: 0.786369 Loss_G: 0.005075\n",
      "[325] Loss_D: 0.831580 Loss_G: 0.005008\n",
      "[326] Loss_D: 0.839916 Loss_G: 0.004951\n",
      "[327] Loss_D: 0.797028 Loss_G: 0.005022\n",
      "[328] Loss_D: 0.801932 Loss_G: 0.004990\n",
      "[329] Loss_D: 0.779806 Loss_G: 0.004995\n",
      "[330] Loss_D: 0.767282 Loss_G: 0.005031\n",
      "[331] Loss_D: 0.792730 Loss_G: 0.005039\n",
      "[332] Loss_D: 0.813015 Loss_G: 0.004973\n",
      "[333] Loss_D: 0.862977 Loss_G: 0.004805\n",
      "[334] Loss_D: 0.838567 Loss_G: 0.004887\n",
      "[335] Loss_D: 0.945315 Loss_G: 0.004620\n",
      "[336] Loss_D: 0.840068 Loss_G: 0.004773\n",
      "[337] Loss_D: 0.794933 Loss_G: 0.004859\n",
      "[338] Loss_D: 0.787611 Loss_G: 0.004829\n",
      "[339] Loss_D: 0.838441 Loss_G: 0.004805\n",
      "[340] Loss_D: 0.854414 Loss_G: 0.004771\n",
      "[341] Loss_D: 0.975956 Loss_G: 0.004511\n",
      "[342] Loss_D: 0.862812 Loss_G: 0.004738\n",
      "[343] Loss_D: 0.799040 Loss_G: 0.004882\n",
      "[344] Loss_D: 0.838046 Loss_G: 0.004809\n",
      "[345] Loss_D: 0.818700 Loss_G: 0.004828\n",
      "[346] Loss_D: 0.855439 Loss_G: 0.004769\n",
      "[347] Loss_D: 0.856402 Loss_G: 0.004761\n",
      "[348] Loss_D: 0.873740 Loss_G: 0.004712\n",
      "[349] Loss_D: 0.921347 Loss_G: 0.004650\n",
      "[350] Loss_D: 0.824572 Loss_G: 0.004844\n",
      "[351] Loss_D: 0.808407 Loss_G: 0.004859\n",
      "[352] Loss_D: 0.817034 Loss_G: 0.004904\n",
      "[353] Loss_D: 0.849663 Loss_G: 0.004848\n",
      "[354] Loss_D: 0.817594 Loss_G: 0.004939\n",
      "[355] Loss_D: 0.917727 Loss_G: 0.004744\n",
      "[356] Loss_D: 0.881017 Loss_G: 0.004797\n",
      "[357] Loss_D: 0.843511 Loss_G: 0.004894\n",
      "[358] Loss_D: 0.827672 Loss_G: 0.004842\n",
      "[359] Loss_D: 0.859176 Loss_G: 0.004839\n",
      "[360] Loss_D: 0.882466 Loss_G: 0.004681\n",
      "[361] Loss_D: 0.926419 Loss_G: 0.004669\n",
      "[362] Loss_D: 0.895369 Loss_G: 0.004726\n",
      "[363] Loss_D: 0.892146 Loss_G: 0.004704\n",
      "[364] Loss_D: 0.941651 Loss_G: 0.004604\n",
      "[365] Loss_D: 0.873254 Loss_G: 0.004714\n",
      "[366] Loss_D: 0.884030 Loss_G: 0.004862\n",
      "[367] Loss_D: 0.818786 Loss_G: 0.004971\n",
      "[368] Loss_D: 0.882937 Loss_G: 0.004837\n",
      "[369] Loss_D: 0.929595 Loss_G: 0.004778\n",
      "[370] Loss_D: 0.964675 Loss_G: 0.004642\n",
      "[371] Loss_D: 0.875391 Loss_G: 0.004767\n",
      "[372] Loss_D: 0.888390 Loss_G: 0.004745\n",
      "[373] Loss_D: 0.939944 Loss_G: 0.004717\n",
      "[374] Loss_D: 1.037833 Loss_G: 0.004451\n",
      "[375] Loss_D: 0.910071 Loss_G: 0.004646\n",
      "[376] Loss_D: 0.871555 Loss_G: 0.004773\n",
      "[377] Loss_D: 0.892823 Loss_G: 0.004696\n",
      "[378] Loss_D: 0.874248 Loss_G: 0.004718\n",
      "[379] Loss_D: 1.000014 Loss_G: 0.004478\n",
      "[380] Loss_D: 0.878377 Loss_G: 0.004665\n",
      "[381] Loss_D: 0.841963 Loss_G: 0.004810\n",
      "[382] Loss_D: 0.860680 Loss_G: 0.004809\n",
      "[383] Loss_D: 0.821686 Loss_G: 0.004778\n",
      "[384] Loss_D: 0.897754 Loss_G: 0.004700\n",
      "[385] Loss_D: 0.889769 Loss_G: 0.004697\n",
      "[386] Loss_D: 0.892929 Loss_G: 0.004602\n",
      "[387] Loss_D: 0.881931 Loss_G: 0.004683\n",
      "[388] Loss_D: 0.838830 Loss_G: 0.004832\n",
      "[389] Loss_D: 0.851975 Loss_G: 0.004770\n",
      "[390] Loss_D: 0.866940 Loss_G: 0.004784\n",
      "[391] Loss_D: 0.827118 Loss_G: 0.004910\n",
      "[392] Loss_D: 0.853923 Loss_G: 0.004857\n",
      "[393] Loss_D: 0.830990 Loss_G: 0.004954\n",
      "[394] Loss_D: 0.871265 Loss_G: 0.004776\n",
      "[395] Loss_D: 0.946583 Loss_G: 0.004561\n",
      "[396] Loss_D: 0.877904 Loss_G: 0.004624\n",
      "[397] Loss_D: 0.854651 Loss_G: 0.004759\n",
      "[398] Loss_D: 0.869999 Loss_G: 0.004655\n",
      "[399] Loss_D: 0.870367 Loss_G: 0.004615\n",
      "[400] Loss_D: 0.833457 Loss_G: 0.004702\n",
      "[401] Loss_D: 0.903433 Loss_G: 0.004557\n",
      "[402] Loss_D: 0.890931 Loss_G: 0.004523\n",
      "[403] Loss_D: 0.800887 Loss_G: 0.004747\n",
      "[404] Loss_D: 0.857757 Loss_G: 0.004586\n",
      "[405] Loss_D: 0.838089 Loss_G: 0.004609\n",
      "[406] Loss_D: 0.816775 Loss_G: 0.004729\n",
      "[407] Loss_D: 0.810358 Loss_G: 0.004706\n",
      "[408] Loss_D: 0.804287 Loss_G: 0.004686\n",
      "[409] Loss_D: 0.860431 Loss_G: 0.004589\n",
      "[410] Loss_D: 0.841786 Loss_G: 0.004598\n",
      "[411] Loss_D: 0.837188 Loss_G: 0.004633\n",
      "[412] Loss_D: 0.836772 Loss_G: 0.004602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413] Loss_D: 0.804616 Loss_G: 0.004672\n",
      "[414] Loss_D: 0.844554 Loss_G: 0.004576\n",
      "[415] Loss_D: 0.921915 Loss_G: 0.004482\n",
      "[416] Loss_D: 0.903950 Loss_G: 0.004426\n",
      "[417] Loss_D: 0.967204 Loss_G: 0.004270\n",
      "[418] Loss_D: 0.888462 Loss_G: 0.004482\n",
      "[419] Loss_D: 0.856518 Loss_G: 0.004531\n",
      "[420] Loss_D: 0.839662 Loss_G: 0.004558\n",
      "[421] Loss_D: 0.902093 Loss_G: 0.004439\n",
      "[422] Loss_D: 0.919930 Loss_G: 0.004389\n",
      "[423] Loss_D: 0.895115 Loss_G: 0.004421\n",
      "[424] Loss_D: 0.883272 Loss_G: 0.004457\n",
      "[425] Loss_D: 0.887609 Loss_G: 0.004430\n",
      "[426] Loss_D: 0.868685 Loss_G: 0.004491\n",
      "[427] Loss_D: 0.835095 Loss_G: 0.004595\n",
      "[428] Loss_D: 0.895646 Loss_G: 0.004467\n",
      "[429] Loss_D: 0.875826 Loss_G: 0.004477\n",
      "[430] Loss_D: 0.946381 Loss_G: 0.004306\n",
      "[431] Loss_D: 0.848941 Loss_G: 0.004544\n",
      "[432] Loss_D: 0.821720 Loss_G: 0.004543\n",
      "[433] Loss_D: 0.886616 Loss_G: 0.004443\n",
      "[434] Loss_D: 0.897580 Loss_G: 0.004369\n",
      "[435] Loss_D: 0.926124 Loss_G: 0.004324\n",
      "[436] Loss_D: 0.907780 Loss_G: 0.004364\n",
      "[437] Loss_D: 0.860598 Loss_G: 0.004428\n",
      "[438] Loss_D: 0.864477 Loss_G: 0.004417\n",
      "[439] Loss_D: 0.847737 Loss_G: 0.004389\n",
      "[440] Loss_D: 0.810690 Loss_G: 0.004486\n",
      "[441] Loss_D: 0.809043 Loss_G: 0.004457\n",
      "[442] Loss_D: 0.817840 Loss_G: 0.004499\n",
      "[443] Loss_D: 0.949902 Loss_G: 0.004209\n",
      "[444] Loss_D: 0.791051 Loss_G: 0.004508\n",
      "[445] Loss_D: 0.838866 Loss_G: 0.004448\n",
      "[446] Loss_D: 0.793464 Loss_G: 0.004519\n",
      "[447] Loss_D: 0.788029 Loss_G: 0.004566\n",
      "[448] Loss_D: 0.796384 Loss_G: 0.004575\n",
      "[449] Loss_D: 0.851238 Loss_G: 0.004471\n",
      "[450] Loss_D: 0.820037 Loss_G: 0.004516\n",
      "[451] Loss_D: 0.799743 Loss_G: 0.004604\n",
      "[452] Loss_D: 0.874473 Loss_G: 0.004501\n",
      "[453] Loss_D: 0.856400 Loss_G: 0.004450\n",
      "[454] Loss_D: 0.831380 Loss_G: 0.004479\n",
      "[455] Loss_D: 0.811535 Loss_G: 0.004582\n",
      "[456] Loss_D: 0.794016 Loss_G: 0.004610\n",
      "[457] Loss_D: 0.841193 Loss_G: 0.004501\n",
      "[458] Loss_D: 0.835170 Loss_G: 0.004506\n",
      "[459] Loss_D: 0.826342 Loss_G: 0.004528\n",
      "[460] Loss_D: 0.815267 Loss_G: 0.004530\n",
      "[461] Loss_D: 0.835837 Loss_G: 0.004506\n",
      "[462] Loss_D: 0.820242 Loss_G: 0.004484\n",
      "[463] Loss_D: 0.831791 Loss_G: 0.004486\n",
      "[464] Loss_D: 0.862339 Loss_G: 0.004463\n",
      "[465] Loss_D: 0.877583 Loss_G: 0.004449\n",
      "[466] Loss_D: 0.879261 Loss_G: 0.004426\n",
      "[467] Loss_D: 0.872430 Loss_G: 0.004431\n",
      "[468] Loss_D: 0.905357 Loss_G: 0.004441\n",
      "[469] Loss_D: 0.903146 Loss_G: 0.004419\n",
      "[470] Loss_D: 0.922626 Loss_G: 0.004340\n",
      "[471] Loss_D: 0.906263 Loss_G: 0.004417\n",
      "[472] Loss_D: 0.880588 Loss_G: 0.004456\n",
      "[473] Loss_D: 0.889961 Loss_G: 0.004486\n",
      "[474] Loss_D: 0.884790 Loss_G: 0.004417\n",
      "[475] Loss_D: 0.895197 Loss_G: 0.004457\n",
      "[476] Loss_D: 0.895657 Loss_G: 0.004399\n",
      "[477] Loss_D: 0.960841 Loss_G: 0.004300\n",
      "[478] Loss_D: 0.854291 Loss_G: 0.004446\n",
      "[479] Loss_D: 0.891284 Loss_G: 0.004487\n",
      "[480] Loss_D: 0.917436 Loss_G: 0.004440\n",
      "[481] Loss_D: 0.891458 Loss_G: 0.004471\n",
      "[482] Loss_D: 0.904035 Loss_G: 0.004478\n",
      "[483] Loss_D: 0.928434 Loss_G: 0.004401\n",
      "[484] Loss_D: 0.900594 Loss_G: 0.004406\n",
      "[485] Loss_D: 0.933981 Loss_G: 0.005000\n",
      "[486] Loss_D: 0.888228 Loss_G: 0.004636\n",
      "[487] Loss_D: 0.831115 Loss_G: 0.004489\n",
      "[488] Loss_D: 0.922345 Loss_G: 0.004274\n",
      "[489] Loss_D: 0.857416 Loss_G: 0.004377\n",
      "[490] Loss_D: 0.899994 Loss_G: 0.004329\n",
      "[491] Loss_D: 0.931717 Loss_G: 0.004307\n",
      "[492] Loss_D: 0.937942 Loss_G: 0.004280\n",
      "[493] Loss_D: 0.892298 Loss_G: 0.004302\n",
      "[494] Loss_D: 0.896589 Loss_G: 0.004327\n",
      "[495] Loss_D: 0.909193 Loss_G: 0.004377\n",
      "[496] Loss_D: 0.898842 Loss_G: 0.004474\n",
      "[497] Loss_D: 0.976716 Loss_G: 0.004308\n",
      "[498] Loss_D: 0.947159 Loss_G: 0.004412\n",
      "[499] Loss_D: 0.880125 Loss_G: 0.004532\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterionMSE = nn.MSELoss()\n",
    "for i in range(500):\n",
    "    discriminator_losses = []\n",
    "    generator_losses = []\n",
    "    for j in range(0, iterator.num_train, 64):        \n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ############################\n",
    "        for disc_updates in range(5):\n",
    "            real_examples_full, real_examples, fake_images = iterator.get_train_minibatch(j, 64)\n",
    "            D1 = discriminator(real_examples)\n",
    "            fake = generator(fake_images)\n",
    "            D2 = discriminator(fake)\n",
    "            \n",
    "            true_labels = torch.ones(D1.size()).cuda()\n",
    "            fake_labels = torch.zeros(D2.size()).cuda()\n",
    "            \n",
    "            # Utilize BCE Loss\n",
    "            real_d_loss = criterion(D1, true_labels).cuda()\n",
    "            fake_d_loss = criterion(D2, fake_labels).cuda()\n",
    "            \n",
    "            discriminator_loss = real_d_loss + fake_d_loss\n",
    "            optimizer_discriminator.zero_grad()\n",
    "            discriminator_loss.backward(retain_graph=True)\n",
    "            \n",
    "            optimizer_discriminator.step()\n",
    "            discriminator_losses.append(discriminator_loss.item())\n",
    "\n",
    "            # clamp parameters to a cube\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ############################\n",
    "        \n",
    "        generated_images = generator(fake_images)\n",
    "        \n",
    "        # Changing Gen Loss to utilize BCE + L2 MSE Loss\n",
    "        gen_bce_loss = criterion(D2, true_labels).cuda()\n",
    "        gen_l2_loss = criterionMSE(fake, real_examples).cuda()\n",
    "        \n",
    "        generator_loss = 0.001*gen_bce_loss + 0.999*gen_l2_loss\n",
    "        \n",
    "        optimizer_generator.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "        generator_losses.append(generator_loss.item())\n",
    "\n",
    "    print('[%d] Loss_D: %f Loss_G: %f' % (i, np.mean(discriminator_losses), np.mean(generator_losses)))\n",
    "    save_plots(i, fake_images, real_examples, real_examples_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'generator_state': generator.state_dict(),\n",
    "    'discriminator_state': discriminator.state_dict(),\n",
    "}\n",
    "torch.save(state, 'inpainting/painter_animal_state_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
